import streamlit as st
import pandas as pd
import logging
import sys
import os
import time
from datetime import datetime
from typing import Dict, List
from research_agent import ResearchAgent
from link_ranker import *
from config import Config
from link_ranker import display_ranked_links
import json
import threading
import threading
from datetime import datetime
import pandas as pd
from typing import List

# Configuration du logging avec plus de dÃ©tails
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Configuration Streamlit
st.set_page_config(
    page_title="Agent de Recherche",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalisÃ© amÃ©liorÃ©
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 15px;
        margin-bottom: 2rem;
        color: white;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    
    .search-box {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 2rem;
        border-radius: 15px;
        border: 1px solid #dee2e6;
        margin: 1rem 0;
        box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    }
    
    .result-box {
        background: white;
        padding: 2rem;
        border-radius: 15px;
        box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        margin: 1rem 0;
        border-left: 5px solid #28a745;
    }
    
    .step-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        margin: 1rem 0;
    }
    
    .step-box {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 12px;
        margin: 0.5rem 0;
        border-left: 4px solid #6c757d;
        transition: all 0.3s ease;
        position: relative;
    }
    
    .step-waiting {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        border-left: 4px solid #6c757d;
        opacity: 0.6;
    }
    
    .step-active {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        border-left: 4px solid #2196f3;
        box-shadow: 0 4px 15px rgba(33, 150, 243, 0.3);
        animation: pulse 2s ease-in-out infinite alternate;
    }
    
    .step-completed {
        background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
        border-left: 4px solid #4caf50;
        box-shadow: 0 4px 15px rgba(76, 175, 80, 0.2);
    }
    
    .step-error {
        background: linear-gradient(135deg, #ffebee 0%, #ffcdd2 100%);
        border-left: 4px solid #f44336;
        box-shadow: 0 4px 15px rgba(244, 67, 54, 0.2);
    }
    
    .step-title {
        font-size: 1.1rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }
    
    .step-details {
        font-size: 0.9rem;
        color: #6c757d;
        margin-top: 0.5rem;
    }
    
    .step-time {
        position: absolute;
        top: 0.5rem;
        right: 1rem;
        font-size: 0.8rem;
        color: #6c757d;
    }
    
    .log-container {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        max-height: 300px;
        overflow-y: auto;
        font-family: 'Courier New', monospace;
        font-size: 0.85rem;
    }
    
    .source-item {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 10px;
        border-left: 4px solid #17a2b8;
        transition: transform 0.2s ease;
    }
    
    .source-item:hover {
        transform: translateX(5px);
    }
    
    @keyframes pulse {
        from { 
            box-shadow: 0 4px 15px rgba(33, 150, 243, 0.3);
        }
        to { 
            box-shadow: 0 4px 25px rgba(33, 150, 243, 0.6);
        }
    }
    
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

def init_session_state():
    """Initialise l'Ã©tat de session"""
    if 'search_history' not in st.session_state:
        st.session_state.search_history = []
    if 'last_result' not in st.session_state:
        st.session_state.last_result = None
    if 'search_running' not in st.session_state:
        st.session_state.search_running = False
    if 'search_steps' not in st.session_state:
        st.session_state.search_steps = {}
    if 'search_logs' not in st.session_state:
        st.session_state.search_logs = []
    if 'search_start_time' not in st.session_state:
        st.session_state.search_start_time = None
    
    # Nouveaux Ã©tats pour la prÃ©visualisation du plan
    if 'preview_plan' not in st.session_state:
        st.session_state.preview_plan = None
    if 'plan_approved' not in st.session_state:
        st.session_state.plan_approved = False
    if 'regenerate_plan' not in st.session_state:
        st.session_state.regenerate_plan = False
    if 'current_query' not in st.session_state:
        st.session_state.current_query = ""
    if 'current_config' not in st.session_state:
        st.session_state.current_config = {}
    
    # Nouveaux Ã©tats pour la recherche contextuelle
    if 'research_context' not in st.session_state:
        st.session_state.research_context = None
    if 'followup_query' not in st.session_state:
        st.session_state.followup_query = ""
    if 'research_chain' not in st.session_state:
        st.session_state.research_chain = []
    if 'contextual_search_active' not in st.session_state:
        st.session_state.contextual_search_active = False

def get_agent(llm_provider: str, search_engines: List[str], scraping_method: str):
    """Obtient un agent configurÃ© selon les paramÃ¨tres"""
    # ClÃ© pour identifier la configuration
    config_key = f"{llm_provider}_{'-'.join(search_engines)}_{scraping_method}"
    
    # VÃ©rifier si on a dÃ©jÃ  un agent avec cette configuration
    if 'agent_config' not in st.session_state or st.session_state.agent_config != config_key:
        # CrÃ©er un nouvel agent avec les bons paramÃ¨tres
        st.session_state.agent = ResearchAgent(
            llm_provider=llm_provider,
            search_engines=search_engines,
            scraping_method=scraping_method
        )
        st.session_state.agent_config = config_key
        logger.info(f"ğŸ”§ Agent reconfigurÃ©: LLM={llm_provider}, Moteurs={search_engines}")
    
    return st.session_state.agent

def display_header():
    """Affiche l'en-tÃªte de l'application"""
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ” Agent de Recherche Intelligent</h1>
        <p>Recherche intelligente avec analyse multi-sources et synthÃ¨se IA</p>
    </div>
    """, unsafe_allow_html=True)

def display_search_interface():
    """Affiche l'interface de recherche"""
    st.markdown('<div class="search-box">', unsafe_allow_html=True)
    
    # Input principal avec gestion de l'historique
    default_query = ""
    if 'selected_query' in st.session_state:
        default_query = st.session_state.selected_query
        del st.session_state.selected_query  # Nettoyer aprÃ¨s utilisation
    
    user_query = st.text_input(
        "ğŸ” Votre question de recherche :",
        value=default_query,
        placeholder="Ex: Intelligence artificielle avantages et inconvÃ©nients",
        help="Posez une question claire et prÃ©cise pour obtenir les meilleurs rÃ©sultats"
    )
    
    # Options avancÃ©es
    with st.expander("âš™ï¸ Options avancÃ©es"):
        col_opt1, col_opt2 = st.columns(2)
        
        with col_opt1:
            deep_search = st.checkbox(
                "ğŸ”¬ Recherche approfondie", 
                value=False,
                help="GÃ©nÃ¨re plus de requÃªtes et analyse plus d'articles (plus lent mais plus complet)"
            )
        
        with col_opt2:
            max_articles = st.slider(
                "ğŸ“° Nombre max d'articles", 
                min_value=3, 
                max_value=15, 
                value=5,
                help="Nombre maximum d'articles Ã  analyser en dÃ©tail"
            )
        
        # Configuration moteurs de recherche et scraping
        col_llm, col_search = st.columns(2)
        
        with col_llm:
            # SÃ©lecteur de modÃ¨le LLM
            llm_provider = st.selectbox(
                "ğŸ¤– ModÃ¨le LLM",
                ["groq", "mistral", "ollama"],
                index=0,  # Groq par dÃ©faut
                help="Groq: Gratuit et rapide | Mistral: Payant mais puissant | Ollama: Local et gratuit"
            )
            
            # Informations sur le modÃ¨le sÃ©lectionnÃ©
            if llm_provider == "groq":
                st.info("ğŸš€ **Groq**: ModÃ¨le Llama gratuit et trÃ¨s rapide")
            elif llm_provider == "mistral":
                st.warning("ğŸ’³ **Mistral**: ModÃ¨le puissant mais payant")
            elif llm_provider == "ollama":
                st.info("ğŸ  **Ollama**: ModÃ¨le local gratuit")
        
        with col_search:
            # SÃ©lecteur de moteurs de recherche
            search_engines = st.multiselect(
                "ğŸ” Moteurs de recherche",
                ["SerpApi"],
                default=["SerpApi"],
                help="SerpApi = Google Search via API officielle (fiable et rapide)"
            )
            
            # MÃ©thode de scraping
            scraping_method = st.selectbox(
                "ğŸ“° MÃ©thode de scraping",
                ["newspaper", "beautifulsoup", "both"],
                index=2,  # Both par dÃ©faut
                help="Newspaper: Plus rapide | BeautifulSoup: Plus robuste | Both: Les deux"
            )
    
    # Configuration avancÃ©e avec presets intelligents
    st.markdown("### âš™ï¸ Configuration avancÃ©e")
    
    # Utiliser les presets de la sidebar si disponibles
    if 'preset_config' in st.session_state:
        preset = st.session_state.preset_config
        default_results = preset['max_results']
        default_articles = preset['max_articles']
        default_queries = preset['max_queries']
        st.info(f"ğŸ¯ Configuration optimisÃ©e activÃ©e: {default_results} rÃ©sultats, {default_articles} articles, {default_queries} requÃªtes")
    else:
        default_results = 10
        default_articles = 5
        default_queries = 6
    
    col_results, col_queries, col_articles = st.columns(3)
    
    with col_results:
        max_results = st.slider(
            "ğŸ”¢ RÃ©sultats par recherche",
            min_value=3,
            max_value=20,
            value=default_results,
            step=1,
            help="Nombre de rÃ©sultats Ã  rÃ©cupÃ©rer pour chaque requÃªte de recherche"
        )
    
    with col_queries:
        max_queries = st.slider(
            "ğŸ“‹ RequÃªtes dans le plan",
            min_value=2,
            max_value=10,
            value=default_queries,
            step=1,
            help="Nombre maximum de requÃªtes gÃ©nÃ©rÃ©es dans le plan de recherche"
        )
    
    with col_articles:
        max_articles = st.slider(
            "ğŸ“° Articles Ã  analyser",
            min_value=2,
            max_value=15,
            value=default_articles,
            step=1,
            help="Nombre d'articles Ã  scraper et analyser en dÃ©tail"
        )
    
    # Boutons et options
    col1, col2, col3, col4 = st.columns([2, 1, 1, 2])
    
    with col1:
        search_button = st.button("ğŸš€ Lancer la recherche", type="primary", use_container_width=True)
    
    with col2:
        if st.button("ğŸ—‘ï¸ Effacer", use_container_width=True, help="Efface les rÃ©sultats et arrÃªte la recherche en cours"):
            # ArrÃªter la recherche en cours
            st.session_state.search_running = False
            
            # Nettoyer complÃ¨tement l'interface
            st.session_state.last_result = None
            st.session_state.search_steps = {}
            st.session_state.search_logs = []
            
            # Nettoyer l'historique si souhaitÃ©
            # st.session_state.search_history = []
            
            # Afficher un message de confirmation
            st.success("ğŸ§¹ Interface nettoyÃ©e ! Recherche arrÃªtÃ©e.")
            st.rerun()
    
    with col3:
        show_logs = st.checkbox("ğŸ“‹ Logs", value=False)
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    return user_query, search_button, show_logs, deep_search, max_articles, llm_provider, search_engines, scraping_method, max_results, max_queries

def add_search_log(message: str, level: str = "info"):
    """Ajoute un log Ã  la liste des logs de recherche"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_entry = {
        "time": timestamp,
        "message": message,
        "level": level
    }
    st.session_state.search_logs.append(log_entry)
    
    # Garder seulement les 50 derniers logs
    if len(st.session_state.search_logs) > 50:
        st.session_state.search_logs = st.session_state.search_logs[-50:]

def update_search_step(step_id: str, status: str, title: str, details: str = "", duration: str = ""):
    """Met Ã  jour une Ã©tape de recherche"""
    st.session_state.search_steps[step_id] = {
        "status": status,
        "title": title,
        "details": details,
        "duration": duration,
        "timestamp": datetime.now().strftime("%H:%M:%S")
    }
    
    # Ajouter au log
    if status == "active":
        add_search_log(f"ğŸ”„ {title} - {details}", "info")
    elif status == "completed":
        add_search_log(f"âœ… {title} terminÃ© - {details}", "success")
    elif status == "error":
        add_search_log(f"âŒ {title} Ã©chouÃ© - {details}", "error")

def display_search_progress():
    """Affiche le progrÃ¨s de la recherche en temps rÃ©el"""
    if not st.session_state.search_steps:
        return
    
    st.markdown("### ğŸš€ Progression de la recherche")
    
    steps_config = [
        {"id": "plan", "icon": "ğŸ“‹", "default_title": "GÃ©nÃ©ration du plan"},
        {"id": "search", "icon": "ğŸ”", "default_title": "Recherche web"},
        {"id": "scraping", "icon": "ğŸ“°", "default_title": "Analyse des articles"},
        {"id": "synthesis", "icon": "âœï¸", "default_title": "SynthÃ¨se finale"}
    ]
    
    # Afficher les Ã©tapes en grille 2x2
    st.markdown('<div class="step-container">', unsafe_allow_html=True)
    
    for i, step_config in enumerate(steps_config):
        step_id = step_config["id"]
        step_data = st.session_state.search_steps.get(step_id, {})
        
        status = step_data.get("status", "waiting")
        title = step_data.get("title", step_config["default_title"])
        details = step_data.get("details", "")
        duration = step_data.get("duration", "")
        timestamp = step_data.get("timestamp", "")
        
        # DÃ©finir la classe CSS selon le statut
        if status == "active":
            step_class = "step-active"
            icon = "â³"
        elif status == "completed":
            step_class = "step-completed"
            icon = "âœ…"
        elif status == "error":
            step_class = "step-error"
            icon = "âŒ"
        else:
            step_class = "step-waiting"
            icon = "â¸ï¸"
        
        # Afficher l'Ã©tape
        st.markdown(f"""
        <div class="{step_class} step-box">
            <div class="step-time">{timestamp}</div>
            <div class="step-title">
                {icon} {step_config['icon']} {title}
            </div>
            <div class="step-details">
                {details}
                {f"<br><small>â±ï¸ {duration}</small>" if duration else ""}
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)

def display_logs(show_logs: bool):
    """Affiche les logs de recherche"""
    if show_logs and st.session_state.search_logs:
        st.markdown("### ğŸ“‹ Logs de recherche")
        
        # Conteneur de logs
        log_html = '<div class="log-container">'
        
        for log in st.session_state.search_logs[-20:]:  # 20 derniers logs
            color = {
                "info": "#17a2b8",
                "success": "#28a745", 
                "error": "#dc3545",
                "warning": "#ffc107"
            }.get(log["level"], "#6c757d")
            
            log_html += f"""
            <div style="margin: 0.2rem 0; color: {color};">
                <span style="color: #6c757d;">[{log['time']}]</span> {log['message']}
            </div>
            """
        
        log_html += '</div>'
        st.markdown(log_html, unsafe_allow_html=True)

class SearchProgressTracker:
    """Classe pour suivre le progrÃ¨s de recherche"""
    
    def __init__(self):
        self.start_time = time.time()
        st.session_state.search_start_time = self.start_time
        st.session_state.search_logs = []
        st.session_state.search_steps = {}
        
    def get_duration(self, start_time):
        """Calcule la durÃ©e Ã©coulÃ©e"""
        duration = time.time() - start_time
        return f"{duration:.1f}s"
    
    def start_step(self, step_id: str, title: str, details: str = ""):
        """DÃ©marre une Ã©tape"""
        self.step_start_time = time.time()
        update_search_step(step_id, "active", title, details)
        
    def complete_step(self, step_id: str, title: str, details: str = ""):
        """Termine une Ã©tape"""
        duration = self.get_duration(self.step_start_time)
        update_search_step(step_id, "completed", title, details, duration)
    
    def error_step(self, step_id: str, title: str, details: str = ""):
        """Marque une Ã©tape comme Ã©chouÃ©e"""
        duration = self.get_duration(self.step_start_time)
        update_search_step(step_id, "error", title, details, duration)
    
    def mark_error(self, step_id: str, title: str, details: str = ""):
        """Alias pour error_step pour compatibilitÃ©"""
        self.error_step(step_id, title, details)
    
    def get_total_duration(self):
        """Calcule la durÃ©e totale depuis le dÃ©but"""
        total_duration = time.time() - self.start_time
        return f"{total_duration:.1f}s"

def research_with_progress_tracking(agent, query, deep_search=False, max_articles=5, search_engines=None, scraping_method="both", max_results=10, max_queries=6, predefined_plan=None):
    """Effectue la recherche avec suivi du progrÃ¨s"""
    tracker = SearchProgressTracker()
    
    if search_engines is None:
        search_engines = ["SerpApi", "SearXNG"]
    
    try:
        # VÃ©rifier si la recherche doit continuer
        if not st.session_state.get('search_running', True):
            logger.info("ğŸ›‘ Recherche interrompue par l'utilisateur")
            return None
        
        # Ã‰tape 1: Utiliser le plan prÃ©dÃ©fini ou en gÃ©nÃ©rer un nouveau
        if predefined_plan:
            # Utiliser le plan approuvÃ© par l'utilisateur
            tracker.start_step("plan", "Utilisation du plan approuvÃ©", "Plan de recherche validÃ© par l'utilisateur")
            plan = predefined_plan
            tracker.complete_step("plan", "Plan utilisÃ©", "Plan de recherche approuvÃ© utilisÃ©")
        else:
            # GÃ©nÃ©ration du plan (mode legacy)
            tracker.start_step("plan", "GÃ©nÃ©ration du plan", "Analyse de votre question avec Mistral AI")
            
            # GÃ©nÃ©rer un plan intelligent (toujours approfondi maintenant)
            plan = agent.llm_client.generate_deep_search_plan(query)
            
            queries_count = len(plan.get("requetes_recherche", [query]))
            mode_text = "approfondie" if deep_search else "standard"
            tracker.complete_step("plan", "Plan gÃ©nÃ©rÃ©", f"{queries_count} requÃªtes de recherche crÃ©Ã©es (mode {mode_text})")
        
        # Limiter le nombre de requÃªtes selon la configuration
        all_queries = plan.get("requetes_recherche", [query])
        limited_queries = all_queries[:max_queries]
        queries_count = len(limited_queries)
        
        # Ã‰tape 2: Recherche web
        tracker.start_step("search", "Recherche web", f"ExÃ©cution de {queries_count} requÃªtes de recherche")
        all_search_results = []
        
        for i, search_query in enumerate(limited_queries, 1):
            # VÃ©rifier si la recherche doit continuer
            if not st.session_state.get('search_running', True):
                logger.info("ğŸ›‘ Recherche interrompue pendant la recherche web")
                return None
                
            add_search_log(f"ğŸ” RequÃªte {i}/{queries_count}: {search_query}")
            results = agent.search_api.search_web(search_query, max_results=max_results, enabled_engines=search_engines)
            all_search_results.extend(results)
            
            # Mise Ã  jour du progrÃ¨s
            progress_details = f"RequÃªte {i}/{queries_count} - {len(results)} rÃ©sultats trouvÃ©s"
            update_search_step("search", "active", "Recherche web", progress_details)
        
        # Supprimer les doublons
        unique_results = []
        seen_urls = set()
        for result in all_search_results:
            if result['url'] not in seen_urls:
                seen_urls.add(result['url'])
                unique_results.append(result)
        
        tracker.complete_step("search", "Recherche terminÃ©e", f"{len(unique_results)} rÃ©sultats uniques trouvÃ©s")
        
        # Ã‰tape 3: Scraping
        # VÃ©rifier si la recherche doit continuer
        if not st.session_state.get('search_running', True):
            logger.info("ğŸ›‘ Recherche interrompue avant le scraping")
            return None
            
        tracker.start_step("scraping", "Analyse des articles", f"Extraction du contenu de {len(unique_results)} sources")
        urls_to_scrape = [result['url'] for result in unique_results[:max_articles * 2]]
        scraped_articles = agent.scraper.scrape_multiple_urls(urls_to_scrape, max_articles=max_articles, method=scraping_method)
        tracker.complete_step("scraping", "Articles analysÃ©s", f"{len(scraped_articles)} articles extraits avec succÃ¨s")
        
        # Ã‰tape 4: SynthÃ¨se
        # VÃ©rifier si la recherche doit continuer
        if not st.session_state.get('search_running', True):
            logger.info("ğŸ›‘ Recherche interrompue avant la synthÃ¨se")
            return None
            
        tracker.start_step("synthesis", "SynthÃ¨se finale", "GÃ©nÃ©ration de la rÃ©ponse avec Mistral AI")
        synthesis = agent.llm_client.synthesize_results(query, unique_results, scraped_articles)
        
        total_duration = tracker.get_duration(tracker.start_time)
        tracker.complete_step("synthesis", "SynthÃ¨se terminÃ©e", f"Recherche complÃ¨te en {total_duration}")
        
        return {
            "user_query": query,  # Nom cohÃ©rent pour le classement
            "query": query,
            "plan": plan,
            "search_results": unique_results,
            "scraped_articles": scraped_articles,
            "synthesis": synthesis,
            "stats": {
                "search_results_count": len(unique_results),
                "scraped_articles_count": len(scraped_articles),
                "search_queries_used": queries_count,
                "total_duration": total_duration
            }
        }
        
    except Exception as e:
        tracker.error_step("synthesis", "Erreur", str(e))
        raise e

def display_results(result):
    """Affiche les rÃ©sultats de recherche"""
    if not result:
        return
    
    # SynthÃ¨se principale
    st.markdown('<div class="result-box">', unsafe_allow_html=True)
    st.markdown("## ğŸ“ SynthÃ¨se des rÃ©sultats")
    st.markdown(result['synthesis'])
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Statistiques en cartes
    st.markdown("### ğŸ“Š Statistiques de la recherche")
    stats = result['stats']
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <h3 style="color: #2196f3; margin: 0;">ğŸ”</h3>
            <h2 style="margin: 0.5rem 0;">{stats['search_results_count']}</h2>
            <p style="margin: 0; color: #6c757d;">Sources trouvÃ©es</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <h3 style="color: #4caf50; margin: 0;">ğŸ“°</h3>
            <h2 style="margin: 0.5rem 0;">{stats['scraped_articles_count']}</h2>
            <p style="margin: 0; color: #6c757d;">Articles analysÃ©s</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <h3 style="color: #ff9800; margin: 0;">ğŸ¯</h3>
            <h2 style="margin: 0.5rem 0;">{stats['search_queries_used']}</h2>
            <p style="margin: 0; color: #6c757d;">RequÃªtes utilisÃ©es</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div class="metric-card">
            <h3 style="color: #9c27b0; margin: 0;">â±ï¸</h3>
            <h2 style="margin: 0.5rem 0;">{stats.get('total_duration', 'N/A')}</h2>
            <p style="margin: 0; color: #6c757d;">DurÃ©e totale</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Plan de recherche
    with st.expander("ğŸ—‚ï¸ Plan de recherche utilisÃ©"):
        plan = result['plan']
        st.write("**StratÃ©gie :**", plan.get('strategie', 'Non disponible'))
        
        if 'requetes_recherche' in plan:
            st.write("**RequÃªtes exÃ©cutÃ©es :**")
            for i, query in enumerate(plan['requetes_recherche'], 1):
                st.write(f"{i}. `{query}`")
    
    # Sources consultÃ©es
    with st.expander(f"ğŸ“š Sources consultÃ©es ({len(result['search_results'])})"):
        for i, source in enumerate(result['search_results'][:15], 1):
            st.markdown(f"""
            <div class="source-item">
                <strong>{i}. {source['title']}</strong><br>
                <small style="color: #6c757d;">{source['url']}</small><br>
                <span style="background: #e3f2fd; padding: 0.2rem 0.5rem; border-radius: 4px; font-size: 0.8rem;">
                    {source['source']}
                </span><br>
                <div style="margin-top: 0.5rem;">
                    {source['snippet'][:250]}...
                </div>
            </div>
            """, unsafe_allow_html=True)
    
    # Articles analysÃ©s
    if result['scraped_articles']:
        with st.expander(f"ğŸ“° Articles analysÃ©s en dÃ©tail ({len(result['scraped_articles'])})"):
            for i, article in enumerate(result['scraped_articles'], 1):
                st.markdown(f"**{i}. {article['title']}**")
                st.write(f"ğŸ”— Source: {article['url']}")
                if article.get('publish_date'):
                    st.write(f"ğŸ“… Date: {article['publish_date']}")
                st.write(f"ğŸ“„ Extrait: {article['content'][:400]}...")
                st.markdown("---")
    
    # Nouveaux tableaux et analyses dÃ©taillÃ©es
    st.markdown("---")
    
    # Onglets pour organiser les analyses dÃ©taillÃ©es
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”— Liens classÃ©s", "ğŸ“Š Tableau dÃ©taillÃ©", "ğŸ”¬ Analyse approfondie", "ğŸ“ˆ MÃ©triques avancÃ©es"])
    
    with tab1:
        display_ranked_links(result)
    
    with tab2:
        display_detailed_results_table(result)
    
    with tab3:
        display_research_insights(result)
    
    with tab4:
        display_advanced_metrics(result)
    
    # NOUVELLE SECTION : Interface de questions de suivi
    display_followup_interface(result)

def display_sidebar():
    """Affiche la sidebar simplifiÃ©e et efficace"""
    with st.sidebar:
        # ğŸš€ Header simple
        st.markdown("""
        <div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin-bottom: 1rem;">
            <h2 style="color: white; margin: 0;">âš™ï¸ ContrÃ´le</h2>
        </div>
        """, unsafe_allow_html=True)
        
        # ğŸ“Š STATUS DES APIS
        st.markdown("### ğŸ“Š Status")
        
        config = Config()
        col1, col2 = st.columns(2)
        
        with col1:
            if config.SERP_API_KEY:
                st.success("ğŸŸ¢ SerpApi")
            else:
                st.error("ğŸ”´ SerpApi")
        
        with col2:
            if config.MISTRAL_API_KEY:
                st.success("ğŸ¤– Mistral")
            else:
                st.warning("âš ï¸ Mistral")
        
        # ğŸ“ˆ STATISTIQUES SESSION
        if 'search_history' in st.session_state:
            searches_count = len(st.session_state.search_history)
        else:
            searches_count = 0
        
        # Status actuel
        if st.session_state.get('search_running', False):
            status_text = "ğŸ”„ Recherche en cours..."
            status_color = "#fff3cd"
        elif st.session_state.get('last_result'):
            status_text = "âœ… DerniÃ¨re recherche OK"
            status_color = "#d4edda"
        else:
            status_text = "ğŸ’¤ En attente"
            status_color = "#e2e3e5"
        
        st.markdown(f"""
        <div style="background: {status_color}; padding: 0.8rem; border-radius: 8px; margin: 1rem 0; text-align: center;">
            <div style="font-weight: bold;">{status_text}</div>
            <div style="font-size: 0.8rem; opacity: 0.8;">Session: {searches_count} recherches</div>
        </div>
        """, unsafe_allow_html=True)
        
        # ğŸ”§ PRESETS RAPIDES
        st.markdown("### ğŸ”§ Configuration")
        
        col_preset1, col_preset2 = st.columns(2)
        
        with col_preset1:
            if st.button("ğŸš€ Rapide", help="5 rÃ©sultats, 3 articles", use_container_width=True):
                st.session_state.preset_config = {
                    'max_results': 5,
                    'max_articles': 3,
                    'max_queries': 3,
                    'deep_search': False
                }
                st.success("âœ… Mode Rapide")
        
        with col_preset2:
            if st.button("ğŸ”¬ Complet", help="15 rÃ©sultats, 8 articles", use_container_width=True):
                st.session_state.preset_config = {
                    'max_results': 15,
                    'max_articles': 8,
                    'max_queries': 6,
                    'deep_search': True
                }
                st.success("âœ… Mode Complet")
        
        # Affichage config active
        if 'preset_config' in st.session_state:
            config = st.session_state.preset_config
            st.info(f"ğŸ“Š {config['max_results']} rÃ©sultats | ğŸ“° {config['max_articles']} articles")
        
        # ğŸ—‚ï¸ HISTORIQUE
        st.markdown("### ğŸ—‚ï¸ Historique")
        
        if st.session_state.get('search_history'):
            # Bouton nettoyer
            if st.button("ğŸ—‘ï¸ Nettoyer", help="Supprimer l'historique"):
                st.session_state.search_history = []
                st.success("ğŸ§¹ NettoyÃ©")
                st.rerun()
            
            # Liste des recherches rÃ©centes
            history = st.session_state.search_history
            recent_searches = history[-8:] if len(history) > 8 else history
            
            for i, query in enumerate(reversed(recent_searches), 1):
                # IcÃ´ne selon le type
                if any(word in query.lower() for word in ['prix', 'acheter', 'meilleur']):
                    icon = "ğŸ›’"
                elif any(word in query.lower() for word in ['actualitÃ©', 'news', '2024']):
                    icon = "ğŸ“°"
                else:
                    icon = "ğŸ”"
                
                # Bouton pour relancer
                query_short = query[:30] + "..." if len(query) > 30 else query
                
                if st.button(f"{icon} {query_short}", key=f"hist_{i}", help=f"Relancer: {query}"):
                    st.session_state.selected_query = query
                    st.rerun()
        else:
            st.markdown("""
            <div style="text-align: center; padding: 1rem; background: #f8f9fa; border-radius: 8px; color: #6c757d;">
                <div style="font-size: 1.5rem;">ğŸ“­</div>
                <div style="font-size: 0.9rem;">Aucune recherche</div>
            </div>
            """, unsafe_allow_html=True)
        
        # ğŸ“ˆ DERNIÃˆRE RECHERCHE (si disponible)
        if st.session_state.get('last_result'):
            st.markdown("### ğŸ“ˆ DerniÃ¨re Recherche")
            
            result = st.session_state.last_result
            stats = result.get('stats', {})
            
            # MÃ©triques simples
            col_stat1, col_stat2 = st.columns(2)
            
            with col_stat1:
                st.metric("ğŸ” Sources", stats.get('search_results_count', 0))
                st.metric("â±ï¸ DurÃ©e", stats.get('total_duration', 'N/A'))
            
            with col_stat2:
                st.metric("ğŸ“° Articles", stats.get('scraped_articles_count', 0))
                st.metric("ğŸ¯ RequÃªtes", stats.get('search_queries_used', 0))
        
        # Footer simple
        st.markdown("---")
        st.markdown("""
        <div style="text-align: center; font-size: 0.7rem; color: #6c757d;">
            Agent v2.0 - SerpApi & Mistral AI
        </div>
        """, unsafe_allow_html=True)

def display_ranked_links(result):
    """Affiche les liens classÃ©s par pertinence avec dÃ©tails"""
    st.markdown("### ğŸ”— Liens trouvÃ©s classÃ©s par pertinence")
    
    if not result.get('search_results'):
        st.warning("Aucun lien trouvÃ©")
        return
    
    # Classifier les liens par pertinence
    ranked_links = rank_links_by_relevance(result['search_results'], result.get('user_query', ''))
    
    # Afficher les statistiques
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ğŸ”— Total liens", len(ranked_links))
    with col2:
        e_commerce_count = sum(1 for link in ranked_links if is_ecommerce_link(link['url']))
        st.metric("ğŸ›’ Sites e-commerce", e_commerce_count)
    with col3:
        amazon_count = sum(1 for link in ranked_links if 'amazon' in link['url'].lower())
        st.metric("ğŸ“¦ Amazon", amazon_count)
    
    # Affichage des liens classÃ©s
    st.markdown("#### ğŸ† Classement des rÃ©sultats (du meilleur au moins bon)")
    
    for i, link in enumerate(ranked_links, 1):
        # Calculer le score de pertinence
        relevance_score = calculate_relevance_score(link, result.get('user_query', ''))
        
        # DÃ©terminer les badges
        badges = get_link_badges(link['url'])
        if badges is None:
            badges = []
        
        # CrÃ©er une carte pour chaque lien
        with st.container():
            # En-tÃªte avec rang et score
            col_rank, col_content = st.columns([1, 9])
            
            with col_rank:
                # MÃ©daille pour les 3 premiers
                if i == 1:
                    st.markdown("# ğŸ¥‡")
                elif i == 2:
                    st.markdown("# ğŸ¥ˆ")
                elif i == 3:
                    st.markdown("# ğŸ¥‰")
                else:
                    st.markdown(f"## #{i}")
            
            with col_content:
                # Titre avec lien cliquable
                st.markdown(f"**[{link['title']}]({link['url']})**")
                
                # Badges
                if badges:  # VÃ©rifier que badges n'est pas vide
                    badge_html = " ".join([f'<span style="background: {color}; color: white; padding: 2px 6px; border-radius: 10px; font-size: 10px; margin-right: 4px;">{text}</span>' 
                                         for text, color in badges])
                    if badge_html:
                        st.markdown(badge_html, unsafe_allow_html=True)
                
                # Description/snippet
                if link.get('snippet'):
                    st.write(f"ğŸ“ {link['snippet'][:200]}{'...' if len(link['snippet']) > 200 else ''}")
                
                # Informations techniques
                col_tech1, col_tech2, col_tech3 = st.columns(3)
                with col_tech1:
                    st.caption(f"â­ Score: {relevance_score:.1f}/10")
                with col_tech2:
                    domain = extract_domain(link['url'])
                    st.caption(f"ğŸŒ {domain}")
                with col_tech3:
                    st.caption(f"ğŸ” Via {link.get('source', 'N/A')}")
        
                    st.markdown("---")
     
    # Actions sur les liens
    st.markdown("#### ğŸ’¾ Actions")
    col_action1, col_action2, col_action3 = st.columns(3)
     
    with col_action1:
        if st.button("ğŸ“‹ Copier le top 5", help="Copier les 5 meilleurs liens"):
            top_5_text = create_top_links_text(ranked_links[:5])
            st.code(top_5_text)
     
    with col_action2:
        if st.button("ğŸ“„ Exporter CSV", help="TÃ©lÃ©charger au format CSV"):
            csv_data = create_csv_export(ranked_links)
            st.download_button(
                label="ğŸ’¾ TÃ©lÃ©charger",
                data=csv_data,
                file_name="liens_classes.csv",
                mime="text/csv"
            )
     
    with col_action3:
        if st.button("ğŸ”— URLs uniquement", help="Liste simple des URLs"):
            urls_text = "\n".join([link['url'] for link in ranked_links[:10]])
            st.code(urls_text)
     
    # Section filtres
    with st.expander("ï¿½ï¿½ Filtrer les rÃ©sultats"):
        col_filter1, col_filter2 = st.columns(2)
        
        with col_filter1:
            # Filtre par type de site
            site_types = st.multiselect(
                "Type de site",
                ["E-commerce", "Blog", "News", "Forum", "Officiel"],
                help="Filtrer par type de site"
            )
        
        with col_filter2:
            # Filtre par domaine
            domains = list(set([extract_domain(link['url']) for link in ranked_links]))
            selected_domains = st.multiselect(
                "Domaines",
                domains[:10],  # Top 10 domaines
                help="Filtrer par domaine spÃ©cifique"
            )

def rank_links_by_relevance(links, query):
    """Classe les liens par pertinence"""
    scored_links = []
    
    for link in links:
        score = calculate_relevance_score(link, query)
        scored_links.append({**link, 'relevance_score': score})
    
    # Trier par score dÃ©croissant
    return sorted(scored_links, key=lambda x: x['relevance_score'], reverse=True)

def calculate_relevance_score(link, query):
    """Calcule un score de pertinence pour un lien"""
    score = 0
    query_words = query.lower().split()
    
    title = link.get('title', '').lower()
    snippet = link.get('snippet', '').lower()
    url = link.get('url', '').lower()
    
    # Points pour les mots de la requÃªte dans le titre (poids fort)
    for word in query_words:
        if word in title:
            score += 3
        if word in snippet:
            score += 2
        if word in url:
            score += 1
    
    # Bonus pour sites e-commerce si c'est une recherche produit
    if is_product_query(query) and is_ecommerce_link(url):
        score += 2
    
    # Bonus spÃ©cial Amazon
    if 'amazon' in url:
        score += 1.5
    
    # Bonus pour les sites populaires
    popular_domains = ['amazon.fr', 'amazon.com', 'leboncoin.fr', 'fnac.com', 'darty.com', 'boulanger.com']
    domain = extract_domain(url)
    if domain in popular_domains:
        score += 1
    
    # Malus pour les liens trop courts (peu d'info)
    if len(snippet) < 50:
        score -= 0.5
    
    return max(0, score)  # Score minimum 0

def is_product_query(query):
    """DÃ©tecte si c'est une recherche de produit"""
    product_keywords = ['meilleur', 'acheter', 'prix', 'pas cher', 'promo', 'solde', 'euro', 'â‚¬', 'test', 'avis', 'comparatif']
    return any(keyword in query.lower() for keyword in product_keywords)

def is_ecommerce_link(url):
    """DÃ©tecte si c'est un site e-commerce"""
    ecommerce_domains = ['amazon', 'fnac', 'darty', 'boulanger', 'cdiscount', 'leboncoin', 'rakuten', 'zalando', 'decathlon']
    return any(domain in url.lower() for domain in ecommerce_domains)

def extract_domain(url):
    """Extrait le domaine d'une URL"""
    try:
        from urllib.parse import urlparse
        return urlparse(url).netloc.replace('www.', '')
    except:
        return url.split('/')[2] if '/' in url else url

def get_link_badges(url):
    """Retourne les badges appropriÃ©s pour un lien"""
    badges = []
    url_lower = url.lower()
    
    if 'amazon' in url_lower:
        badges.append(("AMAZON", "#ff9900"))
    elif any(shop in url_lower for shop in ['fnac', 'darty', 'boulanger']):
        badges.append(("E-COMMERCE", "#007bff"))
    elif 'leboncoin' in url_lower:
        badges.append(("OCCASION", "#28a745"))
    
    if any(word in url_lower for word in ['test', 'review', 'avis']):
        badges.append(("AVIS", "#6f42c1"))
    
    if any(word in url_lower for word in ['promo', 'solde', 'reduction']):
        badges.append(("PROMO", "#dc3545"))
    
    return badges

def create_top_links_text(links):
    """CrÃ©e un texte formatÃ© avec les meilleurs liens"""
    text = "ğŸ† TOP LIENS TROUVÃ‰S\n" + "="*50 + "\n\n"
    
    for i, link in enumerate(links, 1):
        medal = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i}."
        text += f"{medal} {link['title']}\n"
        text += f"   ğŸ”— {link['url']}\n"
        if link.get('snippet'):
            text += f"   ğŸ“ {link['snippet'][:100]}...\n"
        text += "\n"
    
    return text

def create_csv_export(links):
    """CrÃ©e un export CSV des liens"""
    import io
    import csv
    
    output = io.StringIO()
    writer = csv.writer(output)
    
    # En-tÃªtes
    writer.writerow(['Rang', 'Titre', 'URL', 'Domaine', 'Score', 'Snippet', 'Source'])
    
    # DonnÃ©es
    for i, link in enumerate(links, 1):
        writer.writerow([
            i,
            link['title'],
            link['url'],
            extract_domain(link['url']),
            f"{link.get('relevance_score', 0):.1f}",
            link.get('snippet', '')[:200],
            link.get('source', 'N/A')
        ])
    
    return output.getvalue()

def display_detailed_results_table(result):
    """Affiche un tableau dÃ©taillÃ© des rÃ©sultats de recherche"""
    st.markdown("### ğŸ“Š Tableau dÃ©taillÃ© des rÃ©sultats")
    
    # CrÃ©er les donnÃ©es pour le tableau
    table_data = []
    
    # Ajouter les sources de recherche
    for i, source in enumerate(result.get('search_results', []), 1):
        table_data.append({
            'NÂ°': i,
            'Type': 'ğŸ” Source',
            'Titre': source.get('title', 'N/A')[:60] + '...' if len(source.get('title', '')) > 60 else source.get('title', 'N/A'),
            'URL': source.get('url', 'N/A'),
            'Moteur': source.get('source', 'N/A'),
            'Snippet': source.get('snippet', 'N/A')[:100] + '...' if len(source.get('snippet', '')) > 100 else source.get('snippet', 'N/A'),
            'Status': 'âœ… TrouvÃ©'
        })
    
    # Ajouter les articles scrapÃ©s
    for i, article in enumerate(result.get('scraped_articles', []), 1):
        table_data.append({
            'NÂ°': len(result.get('search_results', [])) + i,
            'Type': 'ğŸ“° Article',
            'Titre': article.get('title', 'N/A')[:60] + '...' if len(article.get('title', '')) > 60 else article.get('title', 'N/A'),
            'URL': article.get('url', 'N/A'),
            'Moteur': 'Scraped',
            'Snippet': article.get('content', 'N/A')[:100] + '...' if len(article.get('content', '')) > 100 else article.get('content', 'N/A'),
            'Status': 'âœ… AnalysÃ©'
        })
    
    # CrÃ©er le DataFrame
    if table_data:
        df = pd.DataFrame(table_data)
        
        # Afficher le tableau avec style
        st.dataframe(
            df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "NÂ°": st.column_config.NumberColumn("NÂ°", width="small"),
                "Type": st.column_config.TextColumn("Type", width="small"),
                "Titre": st.column_config.TextColumn("Titre", width="medium"),
                "URL": st.column_config.LinkColumn("URL", width="medium"),
                "Moteur": st.column_config.TextColumn("Moteur", width="small"),
                "Snippet": st.column_config.TextColumn("Extrait", width="large"),
                "Status": st.column_config.TextColumn("Status", width="small")
            }
        )
        
        # Statistiques
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“Š Total rÃ©sultats", len(table_data))
        with col2:
            sources_count = len(result.get('search_results', []))
            st.metric("ğŸ” Sources trouvÃ©es", sources_count)
        with col3:
            articles_count = len(result.get('scraped_articles', []))
            st.metric("ğŸ“° Articles analysÃ©s", articles_count)
        with col4:
            if result.get('plan'):
                queries_count = len(result['plan'].get('requetes_recherche', []))
                st.metric("ğŸ¯ RequÃªtes exÃ©cutÃ©es", queries_count)
    else:
        st.warning("Aucun rÃ©sultat Ã  afficher dans le tableau")

def display_research_insights(result):
    """Affiche des insights dÃ©taillÃ©s sur la recherche"""
    st.markdown("### ğŸ”¬ Analyse approfondie de la recherche")
    
    # Plan de recherche dÃ©taillÃ© et intelligent
    if result.get('plan'):
        plan = result['plan']
        with st.expander("ğŸ“‹ Plan de recherche intelligent", expanded=True):
            # Analyse de la question
            if plan.get('analyse'):
                st.info(f"ğŸ§  **Analyse de votre question :** {plan['analyse']}")
            
            # Plan d'action structurÃ©
            if plan.get('plan_etapes'):
                st.markdown("**ğŸ“Š Plan d'action en Ã©tapes :**")
                for i, etape in enumerate(plan['plan_etapes'], 1):
                    st.markdown(f"  {i}. {etape}")
                st.markdown("---")
            
            # RequÃªtes de recherche
            st.markdown("**ğŸ¯ RequÃªtes de recherche optimisÃ©es :**")
            for i, query in enumerate(plan.get('requetes_recherche', []), 1):
                st.markdown(f"  {i}. `{query}`")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if plan.get('types_sources'):
                    st.markdown("**ğŸ“š Types de sources ciblÃ©es :**")
                    for source_type in plan['types_sources']:
                        st.markdown(f"  â€¢ {source_type}")
            
            with col2:
                if plan.get('questions_secondaires'):
                    st.markdown("**â“ Questions secondaires Ã  explorer :**")
                    for question in plan['questions_secondaires']:
                        st.markdown(f"  â€¢ {question}")
            
            if plan.get('strategie'):
                st.markdown(f"**ğŸ² StratÃ©gie :** {plan['strategie']}")
    
    # Analyse des sources
    if result.get('search_results'):
        with st.expander("ğŸ” Analyse des sources", expanded=True):
            sources = result['search_results']
            
            # RÃ©partition par moteur de recherche
            source_counts = {}
            for source in sources:
                engine = source.get('source', 'Inconnu')
                source_counts[engine] = source_counts.get(engine, 0) + 1
            
            st.markdown("**ğŸ“Š RÃ©partition par moteur de recherche :**")
            for engine, count in source_counts.items():
                percentage = (count / len(sources)) * 100
                st.markdown(f"  â€¢ {engine}: {count} rÃ©sultats ({percentage:.1f}%)")
            
            # Analyse des domaines
            domains = {}
            for source in sources:
                url = source.get('url', '')
                if url:
                    try:
                        domain = url.split('/')[2]
                        domains[domain] = domains.get(domain, 0) + 1
                    except:
                        pass
            
            if domains:
                st.markdown("**ğŸŒ Domaines les plus frÃ©quents :**")
                sorted_domains = sorted(domains.items(), key=lambda x: x[1], reverse=True)
                for domain, count in sorted_domains[:10]:
                    st.markdown(f"  â€¢ {domain}: {count} rÃ©sultat(s)")
    
    # QualitÃ© du scraping
    if result.get('scraped_articles'):
        with st.expander("ğŸ“° QualitÃ© du scraping", expanded=True):
            articles = result['scraped_articles']
            
            # Statistiques de longueur
            lengths = [len(article.get('content', '')) for article in articles]
            if lengths:
                avg_length = sum(lengths) / len(lengths)
                st.markdown(f"**ğŸ“ Longueur moyenne des articles :** {avg_length:.0f} caractÃ¨res")
                st.markdown(f"**ğŸ“ Article le plus long :** {max(lengths)} caractÃ¨res")
                st.markdown(f"**ğŸ“ Article le plus court :** {min(lengths)} caractÃ¨res")
            
            # Articles avec dates
            dated_articles = [a for a in articles if a.get('publish_date')]
            st.markdown(f"**ğŸ“… Articles avec date :** {len(dated_articles)}/{len(articles)}")
            
            # Articles avec auteurs
            authored_articles = [a for a in articles if a.get('authors')]
            st.markdown(f"**ğŸ‘¤ Articles avec auteur :** {len(authored_articles)}/{len(articles)}")

def display_advanced_metrics(result):
    """Affiche des mÃ©triques avancÃ©es sur la recherche"""
    st.markdown("### ğŸ“ˆ MÃ©triques avancÃ©es")
    
    # MÃ©triques de performance
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### âš¡ Performance")
        
        # Calcul du taux de succÃ¨s
        total_searches = len(result.get('search_results', []))
        successful_scrapes = len(result.get('scraped_articles', []))
        
        if total_searches > 0:
            success_rate = (successful_scrapes / total_searches) * 100
            st.metric("ğŸ¯ Taux de succÃ¨s du scraping", f"{success_rate:.1f}%")
        
        # Vitesse de recherche
        if result.get('stats', {}).get('total_duration'):
            duration_str = result['stats']['total_duration']
            try:
                duration_seconds = float(duration_str.replace('s', ''))
                speed = total_searches / duration_seconds if duration_seconds > 0 else 0
                st.metric("ğŸš€ Vitesse de recherche", f"{speed:.1f} rÃ©sultats/s")
            except:
                st.metric("ğŸš€ Vitesse de recherche", "N/A")
        
        # EfficacitÃ© du plan
        if result.get('plan'):
            queries_planned = len(result['plan'].get('requetes_recherche', []))
            queries_used = result.get('stats', {}).get('search_queries_used', 0)
            if queries_planned > 0:
                plan_efficiency = (queries_used / queries_planned) * 100
                st.metric("ğŸ“‹ EfficacitÃ© du plan", f"{plan_efficiency:.1f}%")
    
    with col2:
        st.markdown("#### ğŸ” QualitÃ© des donnÃ©es")
        
        # Richesse du contenu
        if result.get('scraped_articles'):
            articles = result['scraped_articles']
            
            # Longueur moyenne
            lengths = [len(article.get('content', '')) for article in articles]
            if lengths:
                avg_length = sum(lengths) / len(lengths)
                st.metric("ğŸ“ Longueur moyenne", f"{avg_length:.0f} chars")
            
            # DiversitÃ© des sources
            unique_domains = set()
            for article in articles:
                url = article.get('url', '')
                if url:
                    try:
                        domain = url.split('/')[2]
                        unique_domains.add(domain)
                    except:
                        pass
            
            if unique_domains:
                diversity = len(unique_domains) / len(articles) * 100
                st.metric("ğŸŒ DiversitÃ© des sources", f"{diversity:.1f}%")
            
            # FraÃ®cheur des donnÃ©es
            recent_articles = 0
            for article in articles:
                if article.get('publish_date'):
                    # Logique simple pour dÃ©terminer si c'est rÃ©cent
                    recent_articles += 1
            
            if articles:
                freshness = (recent_articles / len(articles)) * 100
                st.metric("ğŸ“… FraÃ®cheur des donnÃ©es", f"{freshness:.1f}%")
    
    # Graphique de rÃ©partition des sources
    if result.get('search_results'):
        st.markdown("#### ğŸ“Š RÃ©partition des sources par moteur")
        
        sources = result['search_results']
        source_counts = {}
        for source in sources:
            engine = source.get('source', 'Inconnu')
            source_counts[engine] = source_counts.get(engine, 0) + 1
        
        # CrÃ©er un DataFrame pour le graphique
        if source_counts:
            chart_data = pd.DataFrame(
                list(source_counts.items()),
                columns=['Moteur', 'Nombre']
            )
            
            # Graphique en barres
            st.bar_chart(chart_data.set_index('Moteur'))
            
            # Tableau de dÃ©tail
            st.markdown("**DÃ©tail par moteur :**")
            for engine, count in sorted(source_counts.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / len(sources)) * 100
                st.write(f"â€¢ **{engine}**: {count} rÃ©sultats ({percentage:.1f}%)")
    
    # Recommandations d'amÃ©lioration
    st.markdown("#### ğŸ’¡ Recommandations")
    
    recommendations = []
    
    # Analyse du taux de succÃ¨s
    if total_searches > 0:
        success_rate = (successful_scrapes / total_searches) * 100
        if success_rate < 50:
            recommendations.append("ğŸ”§ AmÃ©liorer la sÃ©lection des sources pour augmenter le taux de scraping")
        elif success_rate > 80:
            recommendations.append("âœ… Excellent taux de scraping ! Maintenir la qualitÃ©")
    
    # Analyse de la diversitÃ©
    if result.get('scraped_articles'):
        unique_domains = set()
        for article in result['scraped_articles']:
            url = article.get('url', '')
            if url:
                try:
                    domain = url.split('/')[2]
                    unique_domains.add(domain)
                except:
                    pass
        
        if len(unique_domains) < 3:
            recommendations.append("ğŸŒ Diversifier les sources pour obtenir des perspectives variÃ©es")
    
    # Analyse de la longueur
    if result.get('scraped_articles'):
        lengths = [len(article.get('content', '')) for article in result['scraped_articles']]
        if lengths and sum(lengths) / len(lengths) < 500:
            recommendations.append("ğŸ“ Chercher des articles plus dÃ©taillÃ©s pour une meilleure analyse")
    
    if recommendations:
        for rec in recommendations:
            st.write(rec)
    else:
        st.write("âœ… Excellente recherche ! Aucune amÃ©lioration majeure nÃ©cessaire.")

def display_plan_preview(plan, user_query):
    """Affiche la prÃ©visualisation du plan de recherche avec options"""
    st.markdown("### ğŸ“‹ PrÃ©visualisation du plan de recherche")
    
    # Affichage du plan dans un style attractif
    with st.container():
        # En-tÃªte avec la question
        st.info(f"ğŸ¯ **Question analysÃ©e :** {user_query}")
        
        # Analyse de la question (si disponible)
        if plan.get('analyse'):
            st.markdown(f"ğŸ§  **Analyse :** {plan['analyse']}")
        
        # Plan d'action en Ã©tapes
        if plan.get('plan_etapes'):
            st.markdown("**ğŸ“Š Plan d'action :**")
            for i, etape in enumerate(plan['plan_etapes'], 1):
                st.markdown(f"   {i}. {etape}")
        
        # RequÃªtes de recherche prÃ©vues
        st.markdown("**ğŸ” RequÃªtes de recherche qui seront exÃ©cutÃ©es :**")
        queries = plan.get('requetes_recherche', [])
        for i, query in enumerate(queries, 1):
            st.markdown(f"   {i}. `{query}`")
        
        # Informations complÃ©mentaires
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**ğŸ“š Types de sources ciblÃ©es :**")
            for source_type in plan.get('types_sources', []):
                st.markdown(f"   â€¢ {source_type}")
        
        with col2:
            st.markdown("**â“ Questions secondaires :**")
            for question in plan.get('questions_secondaires', []):
                st.markdown(f"   â€¢ {question}")
        
        # StratÃ©gie
        if plan.get('strategie'):
            st.markdown(f"**ğŸ² StratÃ©gie :** {plan['strategie']}")
        
        st.markdown("---")
        
        # Boutons d'action
        col1, col2, col3 = st.columns([2, 2, 1])
        
        with col1:
            if st.button("âœ… Accepter ce plan et lancer la recherche", type="primary", use_container_width=True):
                st.session_state.plan_approved = True
                # Ne pas effacer le plan ici - il sera effacÃ© aprÃ¨s la recherche
                st.rerun()
        
        with col2:
            if st.button("ğŸ”„ GÃ©nÃ©rer un nouveau plan", type="secondary", use_container_width=True):
                st.session_state.regenerate_plan = True
                st.rerun()
        
        with col3:
            if st.button("âŒ Annuler", use_container_width=True):
                st.session_state.preview_plan = None
                st.session_state.plan_approved = False
                st.rerun()
        
        # Message d'aide
        st.markdown("ğŸ’¡ **Conseil :** VÃ©rifiez que les requÃªtes couvrent bien tous les aspects de votre question avant de lancer la recherche.")

def display_followup_interface(result):
    """Affiche l'interface pour poser des questions de suivi"""
    st.markdown("---")
    st.markdown("### ğŸ”„ Questions de suivi")
    st.markdown("Posez une question complÃ©mentaire basÃ©e sur les rÃ©sultats obtenus. L'IA utilisera le contexte de votre recherche prÃ©cÃ©dente.")
    
    # Suggestions de questions basÃ©es sur les rÃ©sultats
    with st.expander("ğŸ’¡ Suggestions de questions de suivi", expanded=False):
        suggestions = generate_followup_suggestions(result)
        st.markdown("**Voici quelques questions que vous pourriez poser :**")
        
        for i, suggestion in enumerate(suggestions, 1):
            col1, col2 = st.columns([3, 1])
            with col1:
                st.markdown(f"{i}. {suggestion}")
            with col2:
                if st.button(f"Utiliser", key=f"suggestion_{i}"):
                    st.session_state.followup_query = suggestion
                    st.rerun()
    
    # Champ de saisie pour la question de suivi
    followup_query = st.text_input(
        "ğŸ¤” Votre question de suivi :",
        value=st.session_state.get('followup_query', ''),
        placeholder="Ex: Quels sont les risques de cette approche ? / Peut-on avoir plus de dÃ©tails sur... ?",
        help="Cette question sera enrichie avec le contexte de votre recherche prÃ©cÃ©dente"
    )
    
    # Boutons d'action
    col1, col2, col3 = st.columns([2, 2, 1])
    
    with col1:
        if st.button("ğŸ” Recherche contextuelle", type="primary", use_container_width=True, disabled=not followup_query.strip()):
            # Lancer une recherche contextuelle
            st.session_state.followup_query = followup_query.strip()
            st.session_state.contextual_search_active = True
            st.session_state.research_context = result
            st.rerun()
    
    with col2:
        if st.button("ğŸ”„ Nouvelle recherche complÃ¨te", type="secondary", use_container_width=True):
            # Effacer le contexte et commencer une nouvelle recherche
            st.session_state.research_context = None
            st.session_state.research_chain = []
            st.session_state.last_result = None
            st.session_state.followup_query = ""
            st.info("ğŸ’« Contexte effacÃ©. Vous pouvez maintenant faire une nouvelle recherche complÃ¨te.")
            st.rerun()
    
    with col3:
        if st.button("ğŸ“‹ Historique", use_container_width=True):
            show_research_chain()
    
    # Afficher la chaÃ®ne de recherches si elle existe
    if st.session_state.research_chain:
        with st.expander(f"ğŸ”— ChaÃ®ne de recherches ({len(st.session_state.research_chain)} Ã©tapes)", expanded=False):
            for i, search_item in enumerate(st.session_state.research_chain, 1):
                st.markdown(f"**{i}. {search_item['type']}:** {search_item['query']}")
                if search_item.get('summary'):
                    st.caption(f"ğŸ“ {search_item['summary'][:100]}...")

def generate_followup_suggestions(result):
    """GÃ©nÃ¨re des suggestions de questions de suivi basÃ©es sur les rÃ©sultats"""
    original_query = result.get('query', '')
    plan = result.get('plan', {})
    
    suggestions = []
    
    # Suggestions basÃ©es sur les questions secondaires du plan
    if plan.get('questions_secondaires'):
        suggestions.extend(plan['questions_secondaires'][:2])
    
    # Suggestions gÃ©nÃ©riques adaptatives
    if 'avantages' in original_query.lower() or 'inconvÃ©nients' in original_query.lower():
        suggestions.append("Quelles sont les alternatives Ã  considÃ©rer ?")
        suggestions.append("Y a-t-il des Ã©tudes rÃ©centes sur ce sujet ?")
    elif 'comment' in original_query.lower():
        suggestions.append("Quels sont les risques ou prÃ©cautions Ã  prendre ?")
        suggestions.append("Combien de temps faut-il pour voir des rÃ©sultats ?")
    elif 'comparaison' in original_query.lower() or 'vs' in original_query.lower():
        suggestions.append("Quels sont les critÃ¨res de choix les plus importants ?")
        suggestions.append("Y a-t-il d'autres options Ã  considÃ©rer ?")
    else:
        suggestions.extend([
            "Quels sont les aspects les plus importants Ã  retenir ?",
            "Y a-t-il des dÃ©veloppements rÃ©cents sur ce sujet ?",
            "Quelles sont les meilleures pratiques recommandÃ©es ?",
            "Peut-on avoir des exemples concrets ?",
            "Quels sont les points de vigilance ?"
        ])
    
    return suggestions[:5]  # Limiter Ã  5 suggestions

def show_research_chain():
    """Affiche la chaÃ®ne complÃ¨te des recherches dans une modal"""
    if st.session_state.research_chain:
        st.markdown("#### ğŸ”— Historique complet des recherches")
        for i, search_item in enumerate(st.session_state.research_chain, 1):
            with st.container():
                st.markdown(f"**Ã‰tape {i} - {search_item['type']}**")
                st.markdown(f"ğŸ¯ **Question :** {search_item['query']}")
                if search_item.get('summary'):
                    st.markdown(f"ğŸ“ **RÃ©sumÃ© :** {search_item['summary']}")
                st.markdown("---")
    else:
        st.info("Aucun historique de recherche pour le moment.")

def contextual_research_with_progress(agent, followup_query, context_result, max_articles=5, search_engines=None, scraping_method="both", max_results=10, max_queries=6):
    """Effectue une recherche contextuelle enrichie avec les rÃ©sultats prÃ©cÃ©dents"""
    tracker = SearchProgressTracker()
    
    if search_engines is None:
        search_engines = ["SerpApi", "SearXNG"]
    
    try:
        # VÃ©rifier si la recherche doit continuer
        if not st.session_state.get('search_running', True):
            logger.info("ğŸ›‘ Recherche contextuelle interrompue par l'utilisateur")
            return None
        
        # Ã‰tape 1: Enrichissement contextuel de la question
        tracker.start_step("context", "Enrichissement contextuel", "Analyse de votre question avec le contexte prÃ©cÃ©dent")
        
        # CrÃ©er un prompt enrichi qui inclut le contexte
        context_prompt = create_contextual_prompt(followup_query, context_result)
        
        # GÃ©nÃ©rer un plan intelligent enrichi avec le contexte
        plan = agent.llm_client.generate_contextual_search_plan(context_prompt, context_result)
        
        # Limiter le nombre de requÃªtes
        all_queries = plan.get("requetes_recherche", [followup_query])
        limited_queries = all_queries[:max_queries]
        queries_count = len(limited_queries)
        
        tracker.complete_step("context", "Contexte intÃ©grÃ©", f"{queries_count} requÃªtes contextuelles gÃ©nÃ©rÃ©es")
        
        # Ã‰tape 2: Recherche web contextuelle
        tracker.start_step("search", "Recherche contextuelle", f"Recherche enrichie avec {queries_count} requÃªtes")
        all_search_results = []
        
        for i, search_query in enumerate(limited_queries, 1):
            if not st.session_state.get('search_running', True):
                logger.info("ğŸ›‘ Recherche interrompue pendant la recherche web contextuelle")
                return None
                
            add_search_log(f"ğŸ” RequÃªte contextuelle {i}/{queries_count}: {search_query}")
            results = agent.search_api.search_web(search_query, max_results=max_results, enabled_engines=search_engines)
            all_search_results.extend(results)
            
            progress_details = f"RequÃªte contextuelle {i}/{queries_count} - {len(results)} rÃ©sultats"
            update_search_step("search", "active", "Recherche contextuelle", progress_details)
        
        # Supprimer les doublons
        unique_results = []
        seen_urls = set()
        for result in all_search_results:
            if result['url'] not in seen_urls:
                seen_urls.add(result['url'])
                unique_results.append(result)
        
        tracker.complete_step("search", "Recherche contextuelle terminÃ©e", f"{len(unique_results)} nouveaux rÃ©sultats trouvÃ©s")
        
        # Ã‰tape 3: Scraping contextuel
        if not st.session_state.get('search_running', True):
            logger.info("ğŸ›‘ Recherche interrompue avant le scraping contextuel")
            return None
            
        tracker.start_step("scraping", "Analyse contextuelle", f"Extraction de {min(len(unique_results), max_articles)} nouvelles sources")
        urls_to_scrape = [result['url'] for result in unique_results[:max_articles * 2]]
        scraped_articles = agent.scraper.scrape_multiple_urls(urls_to_scrape, max_articles=max_articles, method=scraping_method)
        
        tracker.complete_step("scraping", "Articles contextuels analysÃ©s", f"{len(scraped_articles)} nouveaux articles extraits")
        
        # Ã‰tape 4: SynthÃ¨se contextuelle enrichie
        if not st.session_state.get('search_running', True):
            logger.info("ğŸ›‘ Recherche interrompue avant la synthÃ¨se contextuelle")
            return None
            
        tracker.start_step("synthesis", "SynthÃ¨se contextuelle", "IntÃ©gration avec les rÃ©sultats prÃ©cÃ©dents")
        
        # SynthÃ¨se qui intÃ¨gre le contexte prÃ©cÃ©dent
        synthesis = agent.llm_client.synthesize_contextual_results(
            followup_query, 
            unique_results, 
            scraped_articles, 
            context_result
        )
        
        tracker.complete_step("synthesis", "SynthÃ¨se contextuelle terminÃ©e", "RÃ©sultats intÃ©grÃ©s avec le contexte")
        
        # PrÃ©parer le rÃ©sultat final contextuel
        result = {
            "query": followup_query,
            "original_query": context_result.get('query', ''),
            "is_contextual": True,
            "context_summary": context_result.get('synthesis', '')[:300] + "...",
            "plan": plan,
            "search_results": unique_results,
            "scraped_articles": scraped_articles,
            "synthesis": synthesis,
            "stats": {
                "search_results_count": len(unique_results),
                "scraped_articles_count": len(scraped_articles),
                "search_queries_used": len(plan.get("requetes_recherche", [])),
                "total_duration": tracker.get_total_duration()
            }
        }
        
        # Ajouter Ã  la chaÃ®ne de recherches
        add_to_research_chain("Recherche contextuelle", followup_query, synthesis[:200] + "...")
        
        logger.info("âœ… Recherche contextuelle terminÃ©e avec succÃ¨s")
        return result
        
    except Exception as e:
        logger.error(f"âŒ Erreur recherche contextuelle: {e}")
        tracker.mark_error("synthesis", "Erreur synthÃ¨se", str(e))
        raise e

def create_contextual_prompt(followup_query, context_result):
    """CrÃ©e un prompt enrichi avec le contexte de la recherche prÃ©cÃ©dente"""
    original_query = context_result.get('query', '')
    original_synthesis = context_result.get('synthesis', '')[:500]  # Limiter la taille
    
    context_prompt = f"""Question originale: "{original_query}"

RÃ©sumÃ© des rÃ©sultats prÃ©cÃ©dents:
{original_synthesis}

Question de suivi: "{followup_query}"

Contexte: L'utilisateur pose cette question de suivi basÃ©e sur les rÃ©sultats de sa recherche prÃ©cÃ©dente. La nouvelle recherche doit Ãªtre enrichie et complÃ©mentaire."""
    
    return context_prompt

def add_to_research_chain(search_type, query, summary):
    """Ajoute une recherche Ã  la chaÃ®ne d'historique"""
    if 'research_chain' not in st.session_state:
        st.session_state.research_chain = []
    
    st.session_state.research_chain.append({
        'type': search_type,
        'query': query,
        'summary': summary,
        'timestamp': time.strftime("%H:%M:%S")
    })
    
    # Limiter Ã  10 Ã©lÃ©ments pour Ã©viter une chaÃ®ne trop longue
    if len(st.session_state.research_chain) > 10:
        st.session_state.research_chain = st.session_state.research_chain[-10:]

def main():
    """Fonction principale"""
    init_session_state()
    display_header()
    display_sidebar()
    
    # Interface de recherche
    user_query, search_button, show_logs, deep_search, max_articles, llm_provider, search_engines, scraping_method, max_results, max_queries = display_search_interface()
    
    # Afficher le progrÃ¨s s'il y en a un
    if st.session_state.search_steps:
        display_search_progress()
        
        # Bouton d'arrÃªt pendant la recherche
        if st.session_state.get('search_running', False):
            if st.button("ğŸ›‘ ARRÃŠTER LA RECHERCHE", type="secondary", use_container_width=True):
                st.session_state.search_running = False
                add_search_log("ğŸ›‘ Recherche arrÃªtÃ©e par l'utilisateur", "warning")
                st.warning("ğŸ›‘ ArrÃªt de la recherche en cours...")
                st.rerun()
    
    # Afficher les logs en temps rÃ©el si recherche en cours
    if st.session_state.get('search_running', False) or show_logs:
        if st.session_state.search_logs:
            st.markdown("### ğŸ“‹ Logs en temps rÃ©el")
            
            # Conteneur de logs avec scroll automatique
            log_container = st.container()
            with log_container:
                # Afficher les 15 derniers logs
                recent_logs = st.session_state.search_logs[-15:] if len(st.session_state.search_logs) > 15 else st.session_state.search_logs
                
                for log in recent_logs:
                    # Couleurs selon le niveau et contenu
                    if "âœ…" in log["message"] or "rÃ©ussie" in log["message"]:
                        st.success(f"[{log['time']}] {log['message']}")
                    elif "ğŸ›‘" in log["message"] or "interrompue" in log["message"]:
                        st.warning(f"[{log['time']}] {log['message']}")
                    elif "âš ï¸" in log["message"] or "erreur" in log["message"]:
                        st.warning(f"[{log['time']}] {log['message']}")
                    elif "âŒ" in log["message"]:
                        st.error(f"[{log['time']}] {log['message']}")
                    elif "ğŸ”" in log["message"] or "ğŸš€" in log["message"]:
                        st.info(f"[{log['time']}] {log['message']}")
                    else:
                        st.text(f"[{log['time']}] {log['message']}")
                
                # Auto-scroll vers le bas
                if st.session_state.get('search_running', False):
                    st.markdown('<script>window.scrollTo(0, document.body.scrollHeight);</script>', unsafe_allow_html=True)
    
    # ========== NOUVELLE LOGIQUE DE PRÃ‰VISUALISATION DU PLAN ==========
    
    # 1. GÃ‰NÃ‰RATION DU PLAN (premiÃ¨re Ã©tape)
    if search_button and user_query and not st.session_state.get('preview_plan'):
        # Nettoyer l'interface pour la nouvelle recherche
        st.session_state.last_result = None
        st.session_state.search_steps = {}
        st.session_state.search_logs = []
        st.session_state.plan_approved = False
        st.session_state.regenerate_plan = False
        
        # Configurer l'agent
        st.session_state.agent = get_agent(llm_provider, search_engines, scraping_method)
        st.session_state.current_query = user_query
        st.session_state.current_config = {
            'deep_search': deep_search,
            'max_articles': max_articles,
            'search_engines': search_engines,
            'scraping_method': scraping_method,
            'max_results': max_results,
            'max_queries': max_queries,
            'llm_provider': llm_provider
        }
        
        # GÃ©nÃ©rer le plan de recherche
        with st.spinner("ğŸ§  GÃ©nÃ©ration du plan de recherche..."):
            try:
                plan = st.session_state.agent.llm_client.generate_deep_search_plan(user_query)
                st.session_state.preview_plan = plan
                st.success("âœ… Plan de recherche gÃ©nÃ©rÃ© ! VÃ©rifiez-le ci-dessous.")
                st.rerun()
            except Exception as e:
                st.error(f"âŒ Erreur lors de la gÃ©nÃ©ration du plan: {str(e)}")
    
    # 2. RÃ‰GÃ‰NÃ‰RATION DU PLAN (si demandÃ©e)
    if st.session_state.get('regenerate_plan', False):
        st.session_state.regenerate_plan = False
        
        with st.spinner("ğŸ”„ GÃ©nÃ©ration d'un nouveau plan..."):
            try:
                # RÃ©gÃ©nÃ©rer avec un prompt lÃ©gÃ¨rement diffÃ©rent pour avoir de la variÃ©tÃ©
                plan = st.session_state.agent.llm_client.generate_deep_search_plan(st.session_state.current_query)
                st.session_state.preview_plan = plan
                st.success("âœ… Nouveau plan gÃ©nÃ©rÃ© !")
                st.rerun()
            except Exception as e:
                st.error(f"âŒ Erreur lors de la rÃ©gÃ©nÃ©ration: {str(e)}")
    
    # 3. AFFICHAGE DE LA PRÃ‰VISUALISATION
    if st.session_state.get('preview_plan') and not st.session_state.get('plan_approved', False):
        display_plan_preview(st.session_state.preview_plan, st.session_state.current_query)
    
    # 4. LANCEMENT DE LA RECHERCHE (aprÃ¨s approbation du plan)
    if st.session_state.get('plan_approved', False) and st.session_state.get('preview_plan'):
        # Ajouter Ã  l'historique
        if st.session_state.current_query not in st.session_state.search_history:
            st.session_state.search_history.append(st.session_state.current_query)
        
        # Marquer le dÃ©but de la recherche
        st.session_state.search_running = True
        
        # Messages de dÃ©marrage
        add_search_log("ğŸ§¹ Interface nettoyÃ©e - Nouvelle recherche")
        config = st.session_state.current_config
        config_info = f"ğŸ¤– {config['llm_provider'].upper()} | ğŸ” {', '.join(config['search_engines'])} | ğŸ“° {config['scraping_method']}"
        add_search_log(f"âš™ï¸ Configuration: {config_info}")
        add_search_log(f"ğŸ¯ Question: {st.session_state.current_query}")
        add_search_log("ğŸ“‹ Plan de recherche approuvÃ© par l'utilisateur")
        
        # Ajouter Ã  la chaÃ®ne de recherches (premiÃ¨re recherche)
        add_to_research_chain("Recherche initiale", st.session_state.current_query, "Recherche lancÃ©e...")
        
        # Placeholder pour les mises Ã  jour en temps rÃ©el
        progress_placeholder = st.empty()
        
        try:
            # Effectuer la recherche avec suivi (en utilisant le plan approuvÃ©)
            with st.spinner("ğŸ”„ Recherche en cours..."):
                result = research_with_progress_tracking(
                    st.session_state.agent, 
                    st.session_state.current_query, 
                    deep_search=config['deep_search'], 
                    max_articles=config['max_articles'],
                    search_engines=config['search_engines'],
                    scraping_method=config['scraping_method'],
                    max_results=config['max_results'],
                    max_queries=config['max_queries'],
                    predefined_plan=st.session_state.preview_plan  # Passer le plan approuvÃ©
                )
                
                # VÃ©rifier si la recherche a Ã©tÃ© interrompue
                if result is None:
                    st.warning("ğŸ›‘ Recherche interrompue par l'utilisateur")
                    st.session_state.search_running = False
                    return
                
                st.session_state.last_result = result
                
                # Mettre Ã  jour la chaÃ®ne avec le rÃ©sumÃ©
                if st.session_state.research_chain:
                    st.session_state.research_chain[-1]['summary'] = result.get('synthesis', '')[:200] + "..."
            
            st.success("âœ… Recherche terminÃ©e avec succÃ¨s !")
            st.session_state.search_running = False
            
            # Nettoyer les Ã©tats de plan
            st.session_state.plan_approved = False
            st.session_state.preview_plan = None
            
        except Exception as e:
            st.session_state.search_running = False
            st.error(f"âŒ Erreur lors de la recherche: {str(e)}")
            logger.error(f"Erreur recherche: {e}")
            
            # Afficher les dÃ©tails de l'erreur
            with st.expander("ğŸ” DÃ©tails de l'erreur"):
                st.code(str(e))
                st.write("**Logs de debug :**")
                for log in st.session_state.search_logs[-10:]:
                    st.write(f"[{log['time']}] {log['message']}")
    
    # ========== NOUVELLE LOGIQUE DE RECHERCHE CONTEXTUELLE ==========
    
    # 5. GESTION DE LA RECHERCHE CONTEXTUELLE
    if st.session_state.get('contextual_search_active', False):
        st.session_state.contextual_search_active = False
        
        # Nettoyer les logs et Ã©tapes pour la nouvelle recherche
        st.session_state.search_steps = {}
        st.session_state.search_logs = []
        
        # Marquer le dÃ©but de la recherche contextuelle
        st.session_state.search_running = True
        
        # Configurer l'agent (utiliser la config prÃ©cÃ©dente ou par dÃ©faut)
        if not hasattr(st.session_state, 'agent') or st.session_state.agent is None:
            st.session_state.agent = get_agent("mistral", ["SerpApi"], "both")
        
        # Messages de dÃ©marrage pour la recherche contextuelle
        add_search_log("ğŸ”„ DÃ©marrage de la recherche contextuelle")
        add_search_log(f"ğŸ’¡ Question de suivi: {st.session_state.followup_query}")
        add_search_log(f"ğŸ“š Utilisation du contexte de: {st.session_state.research_context.get('query', 'N/A')}")
        
        try:
            # Effectuer la recherche contextuelle
            with st.spinner("ğŸ”„ Recherche contextuelle en cours..."):
                contextual_result = contextual_research_with_progress(
                    st.session_state.agent,
                    st.session_state.followup_query,
                    st.session_state.research_context,
                    max_articles=5,
                    search_engines=["SerpApi"],
                    scraping_method="both",
                    max_results=10,
                    max_queries=4  # Moins de requÃªtes pour les recherches de suivi
                )
                
                # VÃ©rifier si la recherche a Ã©tÃ© interrompue
                if contextual_result is None:
                    st.warning("ğŸ›‘ Recherche contextuelle interrompue par l'utilisateur")
                    st.session_state.search_running = False
                    return
                
                st.session_state.last_result = contextual_result
            
            st.success("âœ… Recherche contextuelle terminÃ©e avec succÃ¨s !")
            st.session_state.search_running = False
            
            # Nettoyer les Ã©tats
            st.session_state.followup_query = ""
            
        except Exception as e:
            st.session_state.search_running = False
            st.error(f"âŒ Erreur lors de la recherche contextuelle: {str(e)}")
            logger.error(f"Erreur recherche contextuelle: {e}")
            
            # Afficher les dÃ©tails de l'erreur
            with st.expander("ğŸ” DÃ©tails de l'erreur"):
                st.code(str(e))
                st.write("**Logs de debug :**")
                for log in st.session_state.search_logs[-10:]:
                    st.write(f"[{log['time']}] {log['message']}")
    
    # Afficher les rÃ©sultats
    if st.session_state.last_result:
        # Afficher un badge pour les rÃ©sultats contextuels
        if st.session_state.last_result.get('is_contextual', False):
            st.info(f"ğŸ”— **RÃ©sultats contextuels** basÃ©s sur votre recherche prÃ©cÃ©dente: \"{st.session_state.last_result.get('original_query', 'N/A')}\"")
        
        display_results(st.session_state.last_result)
    
    # Instructions (seulement si pas de plan en cours et pas de rÃ©sultats)
    if not st.session_state.last_result and not st.session_state.get('preview_plan'):
        st.markdown("""
        ### ğŸ’¡ Guide d'utilisation
        
        1. **Posez votre question** dans le champ ci-dessus
        2. **Cliquez sur "Lancer la recherche"** pour gÃ©nÃ©rer le plan
        3. **VÃ©rifiez le plan de recherche** proposÃ© par l'IA
        4. **Acceptez ou rÃ©gÃ©nÃ©rez** le plan selon vos besoins
        5. **Suivez le progrÃ¨s** en temps rÃ©el avec les Ã©tapes colorÃ©es
        6. **Explorez les rÃ©sultats** avec les sources et articles dÃ©taillÃ©s
        7. **Posez des questions de suivi** pour approfondir sans perdre le contexte
        
        **âœ¨ Exemples de questions efficaces :**
        - `Intelligence artificielle avantages inconvÃ©nients`
        - `TÃ©lÃ©travail impact productivitÃ© 2024`
        - `Changement climatique solutions`
        - `JeÃ»ne intermittent effets santÃ©`
        
        **ğŸ”„ Exemples de questions de suivi :**
        - `Quels sont les risques de cette approche ?`
        - `Peut-on avoir des exemples concrets ?`
        - `Y a-t-il des alternatives ?`
        
        **ğŸ”§ Activez les logs** pour voir les dÃ©tails techniques de la recherche.
        """)

if __name__ == "__main__":
    main() 