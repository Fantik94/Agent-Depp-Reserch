import streamlit as st
import pandas as pd
import logging
import sys
import os
import time
from datetime import datetime
from typing import Dict, List
from research_agent import ResearchAgent
from link_ranker import *
from config import Config
from link_ranker import display_ranked_links
import json
import threading
import threading
from datetime import datetime
import pandas as pd
from typing import List

# Configuration du logging avec plus de d√©tails
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Configuration Streamlit
st.set_page_config(
    page_title="Agent de Recherche",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√© am√©lior√©
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 15px;
        margin-bottom: 2rem;
        color: white;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    
    .search-box {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 2rem;
        border-radius: 15px;
        border: 1px solid #dee2e6;
        margin: 1rem 0;
        box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    }
    
    .result-box {
        background: white;
        padding: 2rem;
        border-radius: 15px;
        box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        margin: 1rem 0;
        border-left: 5px solid #28a745;
    }
    
    .step-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 1rem;
        margin: 1rem 0;
    }
    
    .step-box {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 12px;
        margin: 0.5rem 0;
        border-left: 4px solid #6c757d;
        transition: all 0.3s ease;
        position: relative;
    }
    
    .step-waiting {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        border-left: 4px solid #6c757d;
        opacity: 0.6;
    }
    
    .step-active {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        border-left: 4px solid #2196f3;
        box-shadow: 0 4px 15px rgba(33, 150, 243, 0.3);
        animation: pulse 2s ease-in-out infinite alternate;
    }
    
    .step-completed {
        background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
        border-left: 4px solid #4caf50;
        box-shadow: 0 4px 15px rgba(76, 175, 80, 0.2);
    }
    
    .step-error {
        background: linear-gradient(135deg, #ffebee 0%, #ffcdd2 100%);
        border-left: 4px solid #f44336;
        box-shadow: 0 4px 15px rgba(244, 67, 54, 0.2);
    }
    
    .step-title {
        font-size: 1.1rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }
    
    .step-details {
        font-size: 0.9rem;
        color: #6c757d;
        margin-top: 0.5rem;
    }
    
    .step-time {
        position: absolute;
        top: 0.5rem;
        right: 1rem;
        font-size: 0.8rem;
        color: #6c757d;
    }
    
    .log-container {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        max-height: 300px;
        overflow-y: auto;
        font-family: 'Courier New', monospace;
        font-size: 0.85rem;
    }
    
    .source-item {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 10px;
        border-left: 4px solid #17a2b8;
        transition: transform 0.2s ease;
    }
    
    .source-item:hover {
        transform: translateX(5px);
    }
    
    @keyframes pulse {
        from { 
            box-shadow: 0 4px 15px rgba(33, 150, 243, 0.3);
        }
        to { 
            box-shadow: 0 4px 25px rgba(33, 150, 243, 0.6);
        }
    }
    
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

def init_session_state():
    """Initialise l'√©tat de session"""
    if 'search_history' not in st.session_state:
        st.session_state.search_history = []
    if 'last_result' not in st.session_state:
        st.session_state.last_result = None
    if 'search_running' not in st.session_state:
        st.session_state.search_running = False
    if 'search_steps' not in st.session_state:
        st.session_state.search_steps = {}
    if 'search_logs' not in st.session_state:
        st.session_state.search_logs = []
    if 'search_start_time' not in st.session_state:
        st.session_state.search_start_time = None
    
    # Nouveaux √©tats pour la pr√©visualisation du plan
    if 'preview_plan' not in st.session_state:
        st.session_state.preview_plan = None
    if 'plan_approved' not in st.session_state:
        st.session_state.plan_approved = False
    if 'regenerate_plan' not in st.session_state:
        st.session_state.regenerate_plan = False
    if 'current_query' not in st.session_state:
        st.session_state.current_query = ""
    if 'current_config' not in st.session_state:
        st.session_state.current_config = {}
    
    # Nouveaux √©tats pour la recherche contextuelle
    if 'research_context' not in st.session_state:
        st.session_state.research_context = None
    if 'followup_query' not in st.session_state:
        st.session_state.followup_query = ""
    if 'research_chain' not in st.session_state:
        st.session_state.research_chain = []
    if 'contextual_search_active' not in st.session_state:
        st.session_state.contextual_search_active = False

def get_agent(llm_provider: str, search_engines: List[str], scraping_method: str):
    """Obtient un agent configur√© selon les param√®tres"""
    # Cl√© pour identifier la configuration
    config_key = f"{llm_provider}_{'-'.join(search_engines)}_{scraping_method}"
    
    # V√©rifier si on a d√©j√† un agent avec cette configuration
    if 'agent_config' not in st.session_state or st.session_state.agent_config != config_key:
        # Cr√©er un nouvel agent avec les bons param√®tres
        st.session_state.agent = ResearchAgent(
            llm_provider=llm_provider,
            search_engines=search_engines,
            scraping_method=scraping_method
        )
        st.session_state.agent_config = config_key
        logger.info(f"üîß Agent reconfigur√©: LLM={llm_provider}, Moteurs={search_engines}")
    
    return st.session_state.agent

def display_header():
    """Affiche l'en-t√™te de l'application"""
    st.markdown("""
    <div class="main-header">
        <h1>üîç Agent de Recherche Intelligent</h1>
        <p>Recherche intelligente avec analyse multi-sources et synth√®se IA</p>
    </div>
    """, unsafe_allow_html=True)

def display_search_interface():
    """Affiche l'interface de recherche"""
    st.markdown('<div class="search-box">', unsafe_allow_html=True)
    
    # Input principal avec gestion de l'historique
    default_query = ""
    if 'selected_query' in st.session_state:
        default_query = st.session_state.selected_query
        del st.session_state.selected_query  # Nettoyer apr√®s utilisation
    
    user_query = st.text_input(
        "üîç Votre question de recherche :",
        value=default_query,
        placeholder="Ex: Intelligence artificielle avantages et inconv√©nients",
        help="Posez une question claire et pr√©cise pour obtenir les meilleurs r√©sultats"
    )
    
    # Options avanc√©es
    with st.expander("‚öôÔ∏è Options avanc√©es"):
        col_opt1, col_opt2 = st.columns(2)
        
        with col_opt1:
            deep_search = st.checkbox(
                "üî¨ Recherche approfondie", 
                value=False,
                help="G√©n√®re plus de requ√™tes et analyse plus d'articles (plus lent mais plus complet)"
            )
        
        with col_opt2:
            max_articles = st.slider(
                "üì∞ Nombre max d'articles", 
                min_value=3, 
                max_value=15, 
                value=5,
                help="Nombre maximum d'articles √† analyser en d√©tail"
            )
        
        # Configuration moteurs de recherche et scraping
        col_llm, col_search = st.columns(2)
        
        with col_llm:
            # S√©lecteur de mod√®le LLM
            llm_provider = st.selectbox(
                "ü§ñ Mod√®le LLM",
                ["groq", "mistral", "ollama"],
                index=0,  # Groq par d√©faut
                help="Groq: Gratuit et rapide | Mistral: Payant mais puissant | Ollama: Local et gratuit"
            )
            
            # Informations sur le mod√®le s√©lectionn√©
            if llm_provider == "groq":
                st.info("üöÄ **Groq**: Mod√®le Llama gratuit et tr√®s rapide")
            elif llm_provider == "mistral":
                st.warning("üí≥ **Mistral**: Mod√®le puissant mais payant")
            elif llm_provider == "ollama":
                st.info("üè† **Ollama**: Mod√®le local gratuit")
        
        with col_search:
            # S√©lecteur de moteurs de recherche
            search_engines = st.multiselect(
                "üîç Moteurs de recherche",
                ["SerpApi"],
                default=["SerpApi"],
                help="SerpApi = Google Search via API officielle (fiable et rapide)"
            )
            
            # M√©thode de scraping
            scraping_method = st.selectbox(
                "üì∞ M√©thode de scraping",
                ["newspaper", "beautifulsoup", "both"],
                index=2,  # Both par d√©faut
                help="Newspaper: Plus rapide | BeautifulSoup: Plus robuste | Both: Les deux"
            )
    
    # Configuration avanc√©e avec presets intelligents
    st.markdown("### ‚öôÔ∏è Configuration avanc√©e")
    
    # Utiliser les presets de la sidebar si disponibles
    if 'preset_config' in st.session_state:
        preset = st.session_state.preset_config
        default_results = preset['max_results']
        default_articles = preset['max_articles']
        default_queries = preset['max_queries']
        st.info(f"üéØ Configuration optimis√©e activ√©e: {default_results} r√©sultats, {default_articles} articles, {default_queries} requ√™tes")
    else:
        default_results = 10
        default_articles = 5
        default_queries = 6
    
    col_results, col_queries, col_articles = st.columns(3)
    
    with col_results:
        max_results = st.slider(
            "üî¢ R√©sultats par recherche",
            min_value=3,
            max_value=20,
            value=default_results,
            step=1,
            help="Nombre de r√©sultats √† r√©cup√©rer pour chaque requ√™te de recherche"
        )
    
    with col_queries:
        max_queries = st.slider(
            "üìã Requ√™tes dans le plan",
            min_value=2,
            max_value=10,
            value=default_queries,
            step=1,
            help="Nombre maximum de requ√™tes g√©n√©r√©es dans le plan de recherche"
        )
    
    with col_articles:
        max_articles = st.slider(
            "üì∞ Articles √† analyser",
            min_value=2,
            max_value=15,
            value=default_articles,
            step=1,
            help="Nombre d'articles √† scraper et analyser en d√©tail"
        )
    
    # Boutons et options
    col1, col2, col3, col4 = st.columns([2, 1, 1, 2])
    
    with col1:
        search_button = st.button("üöÄ Lancer la recherche", type="primary", use_container_width=True)
    
    with col2:
        if st.button("üóëÔ∏è Effacer", use_container_width=True, help="Efface les r√©sultats et arr√™te la recherche en cours"):
            # Arr√™ter la recherche en cours
            st.session_state.search_running = False
            
            # Nettoyer compl√®tement l'interface
            st.session_state.last_result = None
            st.session_state.search_steps = {}
            st.session_state.search_logs = []
            
            # Nettoyer l'historique si souhait√©
            # st.session_state.search_history = []
            
            # Afficher un message de confirmation
            st.success("üßπ Interface nettoy√©e ! Recherche arr√™t√©e.")
            st.rerun()
    
    with col3:
        show_logs = st.checkbox("üìã Logs", value=False)
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    return user_query, search_button, show_logs, deep_search, max_articles, llm_provider, search_engines, scraping_method, max_results, max_queries

def add_search_log(message: str, level: str = "info"):
    """Ajoute un log √† la liste des logs de recherche"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_entry = {
        "time": timestamp,
        "message": message,
        "level": level
    }
    st.session_state.search_logs.append(log_entry)
    
    # Garder seulement les 50 derniers logs
    if len(st.session_state.search_logs) > 50:
        st.session_state.search_logs = st.session_state.search_logs[-50:]

def update_search_step(step_id: str, status: str, title: str, details: str = "", duration: str = ""):
    """Met √† jour une √©tape de recherche"""
    st.session_state.search_steps[step_id] = {
        "status": status,
        "title": title,
        "details": details,
        "duration": duration,
        "timestamp": datetime.now().strftime("%H:%M:%S")
    }
    
    # Ajouter au log
    if status == "active":
        add_search_log(f"üîÑ {title} - {details}", "info")
    elif status == "completed":
        add_search_log(f"‚úÖ {title} termin√© - {details}", "success")
    elif status == "error":
        add_search_log(f"‚ùå {title} √©chou√© - {details}", "error")

def display_search_progress():
    """Affiche le progr√®s de la recherche en temps r√©el"""
    if not st.session_state.search_steps:
        return
    
    st.markdown("### üöÄ Progression de la recherche")
    
    steps_config = [
        {"id": "plan", "icon": "üìã", "default_title": "G√©n√©ration du plan"},
        {"id": "search", "icon": "üîç", "default_title": "Recherche web"},
        {"id": "scraping", "icon": "üì∞", "default_title": "Analyse des articles"},
        {"id": "synthesis", "icon": "‚úçÔ∏è", "default_title": "Synth√®se finale"}
    ]
    
    # Afficher les √©tapes en grille 2x2
    st.markdown('<div class="step-container">', unsafe_allow_html=True)
    
    for i, step_config in enumerate(steps_config):
        step_id = step_config["id"]
        step_data = st.session_state.search_steps.get(step_id, {})
        
        status = step_data.get("status", "waiting")
        title = step_data.get("title", step_config["default_title"])
        details = step_data.get("details", "")
        duration = step_data.get("duration", "")
        timestamp = step_data.get("timestamp", "")
        
        # D√©finir la classe CSS selon le statut
        if status == "active":
            step_class = "step-active"
            icon = "‚è≥"
        elif status == "completed":
            step_class = "step-completed"
            icon = "‚úÖ"
        elif status == "error":
            step_class = "step-error"
            icon = "‚ùå"
        else:
            step_class = "step-waiting"
            icon = "‚è∏Ô∏è"
        
        # Afficher l'√©tape
        st.markdown(f"""
        <div class="{step_class} step-box">
            <div class="step-time">{timestamp}</div>
            <div class="step-title">
                {icon} {step_config['icon']} {title}
            </div>
            <div class="step-details">
                {details}
                {f"<br><small>‚è±Ô∏è {duration}</small>" if duration else ""}
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)

def display_logs(show_logs: bool):
    """Affiche les logs de recherche"""
    if show_logs and st.session_state.search_logs:
        st.markdown("### üìã Logs de recherche")
        
        # Conteneur de logs
        log_html = '<div class="log-container">'
        
        for log in st.session_state.search_logs[-20:]:  # 20 derniers logs
            color = {
                "info": "#17a2b8",
                "success": "#28a745", 
                "error": "#dc3545",
                "warning": "#ffc107"
            }.get(log["level"], "#6c757d")
            
            log_html += f"""
            <div style="margin: 0.2rem 0; color: {color};">
                <span style="color: #6c757d;">[{log['time']}]</span> {log['message']}
            </div>
            """
        
        log_html += '</div>'
        st.markdown(log_html, unsafe_allow_html=True)

class SearchProgressTracker:
    """Classe pour suivre le progr√®s de recherche"""
    
    def __init__(self):
        self.start_time = time.time()
        st.session_state.search_start_time = self.start_time
        st.session_state.search_logs = []
        st.session_state.search_steps = {}
        
    def get_duration(self, start_time):
        """Calcule la dur√©e √©coul√©e"""
        duration = time.time() - start_time
        return f"{duration:.1f}s"
    
    def start_step(self, step_id: str, title: str, details: str = ""):
        """D√©marre une √©tape"""
        self.step_start_time = time.time()
        update_search_step(step_id, "active", title, details)
        
    def complete_step(self, step_id: str, title: str, details: str = ""):
        """Termine une √©tape"""
        duration = self.get_duration(self.step_start_time)
        update_search_step(step_id, "completed", title, details, duration)
    
    def error_step(self, step_id: str, title: str, details: str = ""):
        """Marque une √©tape comme √©chou√©e"""
        duration = self.get_duration(self.step_start_time)
        update_search_step(step_id, "error", title, details, duration)
    
    def mark_error(self, step_id: str, title: str, details: str = ""):
        """Alias pour error_step pour compatibilit√©"""
        self.error_step(step_id, title, details)
    
    def get_total_duration(self):
        """Calcule la dur√©e totale depuis le d√©but"""
        total_duration = time.time() - self.start_time
        return f"{total_duration:.1f}s"

def research_with_progress_tracking(agent, query, deep_search=False, max_articles=5, search_engines=None, scraping_method="both", max_results=10, max_queries=6, predefined_plan=None):
    """Effectue la recherche avec suivi du progr√®s"""
    tracker = SearchProgressTracker()
    
    if search_engines is None:
        search_engines = ["SerpApi", "SearXNG"]
    
    try:
        # V√©rifier si la recherche doit continuer
        if not st.session_state.get('search_running', True):
            logger.info("üõë Recherche interrompue par l'utilisateur")
            return None
        
        # √âtape 1: Utiliser le plan pr√©d√©fini ou en g√©n√©rer un nouveau
        if predefined_plan:
            # Utiliser le plan approuv√© par l'utilisateur
            tracker.start_step("plan", "Utilisation du plan approuv√©", "Plan de recherche valid√© par l'utilisateur")
            plan = predefined_plan
            tracker.complete_step("plan", "Plan utilis√©", "Plan de recherche approuv√© utilis√©")
        else:
            # G√©n√©ration du plan (mode legacy)
            tracker.start_step("plan", "G√©n√©ration du plan", "Analyse de votre question avec Mistral AI")
            
            # G√©n√©rer un plan intelligent (toujours approfondi maintenant)
            plan = agent.llm_client.generate_deep_search_plan(query)
            
            queries_count = len(plan.get("requetes_recherche", [query]))
            mode_text = "approfondie" if deep_search else "standard"
            tracker.complete_step("plan", "Plan g√©n√©r√©", f"{queries_count} requ√™tes de recherche cr√©√©es (mode {mode_text})")
        
        # Limiter le nombre de requ√™tes selon la configuration
        all_queries = plan.get("requetes_recherche", [query])
        limited_queries = all_queries[:max_queries]
        queries_count = len(limited_queries)
        
        # √âtape 2: Recherche web
        tracker.start_step("search", "Recherche web", f"Ex√©cution de {queries_count} requ√™tes de recherche")
        all_search_results = []
        
        for i, search_query in enumerate(limited_queries, 1):
            # V√©rifier si la recherche doit continuer
            if not st.session_state.get('search_running', True):
                logger.info("üõë Recherche interrompue pendant la recherche web")
                return None
                
            add_search_log(f"üîç Requ√™te {i}/{queries_count}: {search_query}")
            results = agent.search_api.search_web(search_query, max_results=max_results, enabled_engines=search_engines)
            all_search_results.extend(results)
            
            # Mise √† jour du progr√®s
            progress_details = f"Requ√™te {i}/{queries_count} - {len(results)} r√©sultats trouv√©s"
            update_search_step("search", "active", "Recherche web", progress_details)
        
        # Supprimer les doublons
        unique_results = []
        seen_urls = set()
        for result in all_search_results:
            if result['url'] not in seen_urls:
                seen_urls.add(result['url'])
                unique_results.append(result)
        
        tracker.complete_step("search", "Recherche termin√©e", f"{len(unique_results)} r√©sultats uniques trouv√©s")
        
        # √âtape 3: Scraping
        # V√©rifier si la recherche doit continuer
        if not st.session_state.get('search_running', True):
            logger.info("üõë Recherche interrompue avant le scraping")
            return None
            
        tracker.start_step("scraping", "Analyse des articles", f"Extraction du contenu de {len(unique_results)} sources")
        urls_to_scrape = [result['url'] for result in unique_results[:max_articles * 2]]
        scraped_articles = agent.scraper.scrape_multiple_urls(urls_to_scrape, max_articles=max_articles, method=scraping_method)
        tracker.complete_step("scraping", "Articles analys√©s", f"{len(scraped_articles)} articles extraits avec succ√®s")
        
        # √âtape 4: Synth√®se
        # V√©rifier si la recherche doit continuer
        if not st.session_state.get('search_running', True):
            logger.info("üõë Recherche interrompue avant la synth√®se")
            return None
            
        tracker.start_step("synthesis", "Synth√®se finale", "G√©n√©ration de la r√©ponse avec Mistral AI")
        synthesis = agent.llm_client.synthesize_results(query, unique_results, scraped_articles)
        
        total_duration = tracker.get_duration(tracker.start_time)
        tracker.complete_step("synthesis", "Synth√®se termin√©e", f"Recherche compl√®te en {total_duration}")
        
        return {
            "user_query": query,  # Nom coh√©rent pour le classement
            "query": query,
            "plan": plan,
            "search_results": unique_results,
            "scraped_articles": scraped_articles,
            "synthesis": synthesis,
            "stats": {
                "search_results_count": len(unique_results),
                "scraped_articles_count": len(scraped_articles),
                "search_queries_used": queries_count,
                "total_duration": total_duration
            }
        }
        
    except Exception as e:
        tracker.error_step("synthesis", "Erreur", str(e))
        raise e

def display_results(result):
    """Affiche les r√©sultats de recherche"""
    if not result:
        return
    
    # Synth√®se principale
    st.markdown('<div class="result-box">', unsafe_allow_html=True)
    st.markdown("## üìù Synth√®se des r√©sultats")
    st.markdown(result['synthesis'])
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Statistiques en cartes
    st.markdown("### üìä Statistiques de la recherche")
    stats = result['stats']
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <h3 style="color: #2196f3; margin: 0;">üîç</h3>
            <h2 style="margin: 0.5rem 0;">{stats['search_results_count']}</h2>
            <p style="margin: 0; color: #6c757d;">Sources trouv√©es</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <h3 style="color: #4caf50; margin: 0;">üì∞</h3>
            <h2 style="margin: 0.5rem 0;">{stats['scraped_articles_count']}</h2>
            <p style="margin: 0; color: #6c757d;">Articles analys√©s</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <h3 style="color: #ff9800; margin: 0;">üéØ</h3>
            <h2 style="margin: 0.5rem 0;">{stats['search_queries_used']}</h2>
            <p style="margin: 0; color: #6c757d;">Requ√™tes utilis√©es</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div class="metric-card">
            <h3 style="color: #9c27b0; margin: 0;">‚è±Ô∏è</h3>
            <h2 style="margin: 0.5rem 0;">{stats.get('total_duration', 'N/A')}</h2>
            <p style="margin: 0; color: #6c757d;">Dur√©e totale</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Plan de recherche
    with st.expander("üóÇÔ∏è Plan de recherche utilis√©"):
        plan = result['plan']
        st.write("**Strat√©gie :**", plan.get('strategie', 'Non disponible'))
        
        if 'requetes_recherche' in plan:
            st.write("**Requ√™tes ex√©cut√©es :**")
            for i, query in enumerate(plan['requetes_recherche'], 1):
                st.write(f"{i}. `{query}`")
    
    # Sources consult√©es
    with st.expander(f"üìö Sources consult√©es ({len(result['search_results'])})"):
        for i, source in enumerate(result['search_results'][:15], 1):
            st.markdown(f"""
            <div class="source-item">
                <strong>{i}. {source['title']}</strong><br>
                <small style="color: #6c757d;">{source['url']}</small><br>
                <span style="background: #e3f2fd; padding: 0.2rem 0.5rem; border-radius: 4px; font-size: 0.8rem;">
                    {source['source']}
                </span><br>
                <div style="margin-top: 0.5rem;">
                    {source['snippet'][:250]}...
                </div>
            </div>
            """, unsafe_allow_html=True)
    
    # Articles analys√©s
    if result['scraped_articles']:
        with st.expander(f"üì∞ Articles analys√©s en d√©tail ({len(result['scraped_articles'])})"):
            for i, article in enumerate(result['scraped_articles'], 1):
                st.markdown(f"**{i}. {article['title']}**")
                st.write(f"üîó Source: {article['url']}")
                if article.get('publish_date'):
                    st.write(f"üìÖ Date: {article['publish_date']}")
                st.write(f"üìÑ Extrait: {article['content'][:400]}...")
                st.markdown("---")
    
    # Nouveaux tableaux et analyses d√©taill√©es
    st.markdown("---")
    
    # Onglets pour organiser les analyses d√©taill√©es
    tab1, tab2, tab3, tab4 = st.tabs(["üîó Liens class√©s", "üìä Tableau d√©taill√©", "üî¨ Analyse approfondie", "üìà M√©triques avanc√©es"])
    
    with tab1:
        display_ranked_links(result)
    
    with tab2:
        display_detailed_results_table(result)
    
    with tab3:
        display_research_insights(result)
    
    with tab4:
        display_advanced_metrics(result)
    
    # NOUVELLE SECTION : Interface de questions de suivi
    display_followup_interface(result)

def display_sidebar():
    """Affiche la sidebar simplifi√©e et efficace"""
    with st.sidebar:
        # üöÄ Header simple
        st.markdown("""
        <div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin-bottom: 1rem;">
            <h2 style="color: white; margin: 0;">‚öôÔ∏è Contr√¥le</h2>
        </div>
        """, unsafe_allow_html=True)
        
        # üìä STATUS DES APIS
        st.markdown("### üìä Status")
        
        config = Config()
        col1, col2 = st.columns(2)
        
        with col1:
            if config.SERP_API_KEY:
                st.success("üü¢ SerpApi")
            else:
                st.error("üî¥ SerpApi")
        
        with col2:
            if config.MISTRAL_API_KEY:
                st.success("ü§ñ Mistral")
            else:
                st.warning("‚ö†Ô∏è Mistral")
        
        # üìà STATISTIQUES SESSION
        if 'search_history' in st.session_state:
            searches_count = len(st.session_state.search_history)
        else:
            searches_count = 0
        
        # Status actuel
        if st.session_state.get('search_running', False):
            status_text = "üîÑ Recherche en cours..."
            status_color = "#fff3cd"
        elif st.session_state.get('last_result'):
            status_text = "‚úÖ Derni√®re recherche OK"
            status_color = "#d4edda"
        else:
            status_text = "üí§ En attente"
            status_color = "#e2e3e5"
        
        st.markdown(f"""
        <div style="background: {status_color}; padding: 0.8rem; border-radius: 8px; margin: 1rem 0; text-align: center;">
            <div style="font-weight: bold;">{status_text}</div>
            <div style="font-size: 0.8rem; opacity: 0.8;">Session: {searches_count} recherches</div>
        </div>
        """, unsafe_allow_html=True)
        
        # üîß PRESETS RAPIDES
        st.markdown("### üîß Configuration")
        
        col_preset1, col_preset2 = st.columns(2)
        
        with col_preset1:
            if st.button("üöÄ Rapide", help="5 r√©sultats, 3 articles", use_container_width=True):
                st.session_state.preset_config = {
                    'max_results': 5,
                    'max_articles': 3,
                    'max_queries': 3,
                    'deep_search': False
                }
                st.success("‚úÖ Mode Rapide")
        
        with col_preset2:
            if st.button("üî¨ Complet", help="15 r√©sultats, 8 articles", use_container_width=True):
                st.session_state.preset_config = {
                    'max_results': 15,
                    'max_articles': 8,
                    'max_queries': 6,
                    'deep_search': True
                }
                st.success("‚úÖ Mode Complet")
        
        # Affichage config active
        if 'preset_config' in st.session_state:
            config = st.session_state.preset_config
            st.info(f"üìä {config['max_results']} r√©sultats | üì∞ {config['max_articles']} articles")
        
        # üóÇÔ∏è HISTORIQUE
        st.markdown("### üóÇÔ∏è Historique")
        
        if st.session_state.get('search_history'):
            # Bouton nettoyer
            if st.button("üóëÔ∏è Nettoyer", help="Supprimer l'historique"):
                st.session_state.search_history = []
                st.success("üßπ Nettoy√©")
                st.rerun()
            
            # Liste des recherches r√©centes
            history = st.session_state.search_history
            recent_searches = history[-8:] if len(history) > 8 else history
            
            for i, query in enumerate(reversed(recent_searches), 1):
                # Ic√¥ne selon le type
                if any(word in query.lower() for word in ['prix', 'acheter', 'meilleur']):
                    icon = "üõí"
                elif any(word in query.lower() for word in ['actualit√©', 'news', '2024']):
                    icon = "üì∞"
                else:
                    icon = "üîç"
                
                # Bouton pour relancer
                query_short = query[:30] + "..." if len(query) > 30 else query
                
                if st.button(f"{icon} {query_short}", key=f"hist_{i}", help=f"Relancer: {query}"):
                    st.session_state.selected_query = query
                    st.rerun()
        else:
            st.markdown("""
            <div style="text-align: center; padding: 1rem; background: #f8f9fa; border-radius: 8px; color: #6c757d;">
                <div style="font-size: 1.5rem;">üì≠</div>
                <div style="font-size: 0.9rem;">Aucune recherche</div>
            </div>
            """, unsafe_allow_html=True)
        
        # üìà DERNI√àRE RECHERCHE (si disponible)
        if st.session_state.get('last_result'):
            st.markdown("### üìà Derni√®re Recherche")
            
            result = st.session_state.last_result
            stats = result.get('stats', {})
            
            # M√©triques simples
            col_stat1, col_stat2 = st.columns(2)
            
            with col_stat1:
                st.metric("üîç Sources", stats.get('search_results_count', 0))
                st.metric("‚è±Ô∏è Dur√©e", stats.get('total_duration', 'N/A'))
            
            with col_stat2:
                st.metric("üì∞ Articles", stats.get('scraped_articles_count', 0))
                st.metric("üéØ Requ√™tes", stats.get('search_queries_used', 0))
        
        # Footer simple
        st.markdown("---")
        st.markdown("""
        <div style="text-align: center; font-size: 0.7rem; color: #6c757d;">
            Agent v2.0 - SerpApi & Mistral AI
        </div>
        """, unsafe_allow_html=True)

def display_ranked_links(result):
    """Affiche les liens class√©s par pertinence avec d√©tails"""
    st.markdown("### üîó Liens trouv√©s class√©s par pertinence")
    
    if not result.get('search_results'):
        st.warning("Aucun lien trouv√©")
        return
    
    # Classifier les liens par pertinence
    ranked_links = rank_links_by_relevance(result['search_results'], result.get('user_query', ''))
    
    # Afficher les statistiques
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üîó Total liens", len(ranked_links))
    with col2:
        e_commerce_count = sum(1 for link in ranked_links if is_ecommerce_link(link['url']))
        st.metric("üõí Sites e-commerce", e_commerce_count)
    with col3:
        amazon_count = sum(1 for link in ranked_links if 'amazon' in link['url'].lower())
        st.metric("üì¶ Amazon", amazon_count)
    
    # Affichage des liens class√©s
    st.markdown("#### üèÜ Classement des r√©sultats (du meilleur au moins bon)")
    
    for i, link in enumerate(ranked_links, 1):
        # Calculer le score de pertinence
        relevance_score = calculate_relevance_score(link, result.get('user_query', ''))
        
        # D√©terminer les badges
        badges = get_link_badges(link['url'])
        if badges is None:
            badges = []
        
        # Cr√©er une carte pour chaque lien
        with st.container():
            # En-t√™te avec rang et score
            col_rank, col_content = st.columns([1, 9])
            
            with col_rank:
                # M√©daille pour les 3 premiers
                if i == 1:
                    st.markdown("# ü•á")
                elif i == 2:
                    st.markdown("# ü•à")
                elif i == 3:
                    st.markdown("# ü•â")
                else:
                    st.markdown(f"## #{i}")
            
            with col_content:
                # Titre avec lien cliquable
                st.markdown(f"**[{link['title']}]({link['url']})**")
                
                # Badges
                if badges:  # V√©rifier que badges n'est pas vide
                    badge_html = " ".join([f'<span style="background: {color}; color: white; padding: 2px 6px; border-radius: 10px; font-size: 10px; margin-right: 4px;">{text}</span>' 
                                         for text, color in badges])
                    if badge_html:
                        st.markdown(badge_html, unsafe_allow_html=True)
                
                # Description/snippet
                if link.get('snippet'):
                    st.write(f"üìù {link['snippet'][:200]}{'...' if len(link['snippet']) > 200 else ''}")
                
                # Informations techniques
                col_tech1, col_tech2, col_tech3 = st.columns(3)
                with col_tech1:
                    st.caption(f"‚≠ê Score: {relevance_score:.1f}/10")
                with col_tech2:
                    domain = extract_domain(link['url'])
                    st.caption(f"üåê {domain}")
                with col_tech3:
                    st.caption(f"üîç Via {link.get('source', 'N/A')}")
        
                    st.markdown("---")
     
    # Actions sur les liens
    st.markdown("#### üíæ Actions")
    col_action1, col_action2, col_action3 = st.columns(3)
     
    with col_action1:
        if st.button("üìã Copier le top 5", help="Copier les 5 meilleurs liens"):
            top_5_text = create_top_links_text(ranked_links[:5])
            st.code(top_5_text)
     
    with col_action2:
        if st.button("üìÑ Exporter CSV", help="T√©l√©charger au format CSV"):
            csv_data = create_csv_export(ranked_links)
            st.download_button(
                label="üíæ T√©l√©charger",
                data=csv_data,
                file_name="liens_classes.csv",
                mime="text/csv"
            )
     
    with col_action3:
        if st.button("üîó URLs uniquement", help="Liste simple des URLs"):
            urls_text = "\n".join([link['url'] for link in ranked_links[:10]])
            st.code(urls_text)
     
    # Section filtres
    with st.expander("ÔøΩÔøΩ Filtrer les r√©sultats"):
        col_filter1, col_filter2 = st.columns(2)
        
        with col_filter1:
            # Filtre par type de site
            site_types = st.multiselect(
                "Type de site",
                ["E-commerce", "Blog", "News", "Forum", "Officiel"],
                help="Filtrer par type de site"
            )
        
        with col_filter2:
            # Filtre par domaine
            domains = list(set([extract_domain(link['url']) for link in ranked_links]))
            selected_domains = st.multiselect(
                "Domaines",
                domains[:10],  # Top 10 domaines
                help="Filtrer par domaine sp√©cifique"
            )

def rank_links_by_relevance(links, query):
    """Classe les liens par pertinence"""
    scored_links = []
    
    for link in links:
        score = calculate_relevance_score(link, query)
        scored_links.append({**link, 'relevance_score': score})
    
    # Trier par score d√©croissant
    return sorted(scored_links, key=lambda x: x['relevance_score'], reverse=True)

def calculate_relevance_score(link, query):
    """Calcule un score de pertinence pour un lien"""
    score = 0
    query_words = query.lower().split()
    
    title = link.get('title', '').lower()
    snippet = link.get('snippet', '').lower()
    url = link.get('url', '').lower()
    
    # Points pour les mots de la requ√™te dans le titre (poids fort)
    for word in query_words:
        if word in title:
            score += 3
        if word in snippet:
            score += 2
        if word in url:
            score += 1
    
    # Bonus pour sites e-commerce si c'est une recherche produit
    if is_product_query(query) and is_ecommerce_link(url):
        score += 2
    
    # Bonus sp√©cial Amazon
    if 'amazon' in url:
        score += 1.5
    
    # Bonus pour les sites populaires
    popular_domains = ['amazon.fr', 'amazon.com', 'leboncoin.fr', 'fnac.com', 'darty.com', 'boulanger.com']
    domain = extract_domain(url)
    if domain in popular_domains:
        score += 1
    
    # Malus pour les liens trop courts (peu d'info)
    if len(snippet) < 50:
        score -= 0.5
    
    return max(0, score)  # Score minimum 0

def is_product_query(query):
    """D√©tecte si c'est une recherche de produit"""
    product_keywords = ['meilleur', 'acheter', 'prix', 'pas cher', 'promo', 'solde', 'euro', '‚Ç¨', 'test', 'avis', 'comparatif']
    return any(keyword in query.lower() for keyword in product_keywords)

def is_ecommerce_link(url):
    """D√©tecte si c'est un site e-commerce"""
    ecommerce_domains = ['amazon', 'fnac', 'darty', 'boulanger', 'cdiscount', 'leboncoin', 'rakuten', 'zalando', 'decathlon']
    return any(domain in url.lower() for domain in ecommerce_domains)

def extract_domain(url):
    """Extrait le domaine d'une URL"""
    try:
        from urllib.parse import urlparse
        return urlparse(url).netloc.replace('www.', '')
    except:
        return url.split('/')[2] if '/' in url else url

def get_link_badges(url):
    """Retourne les badges appropri√©s pour un lien"""
    badges = []
    url_lower = url.lower()
    
    if 'amazon' in url_lower:
        badges.append(("AMAZON", "#ff9900"))
    elif any(shop in url_lower for shop in ['fnac', 'darty', 'boulanger']):
        badges.append(("E-COMMERCE", "#007bff"))
    elif 'leboncoin' in url_lower:
        badges.append(("OCCASION", "#28a745"))
    
    if any(word in url_lower for word in ['test', 'review', 'avis']):
        badges.append(("AVIS", "#6f42c1"))
    
    if any(word in url_lower for word in ['promo', 'solde', 'reduction']):
        badges.append(("PROMO", "#dc3545"))
    
    return badges

def create_top_links_text(links):
    """Cr√©e un texte format√© avec les meilleurs liens"""
    text = "üèÜ TOP LIENS TROUV√âS\n" + "="*50 + "\n\n"
    
    for i, link in enumerate(links, 1):
        medal = "ü•á" if i == 1 else "ü•à" if i == 2 else "ü•â" if i == 3 else f"{i}."
        text += f"{medal} {link['title']}\n"
        text += f"   üîó {link['url']}\n"
        if link.get('snippet'):
            text += f"   üìù {link['snippet'][:100]}...\n"
        text += "\n"
    
    return text

def create_csv_export(links):
    """Cr√©e un export CSV des liens"""
    import io
    import csv
    
    output = io.StringIO()
    writer = csv.writer(output)
    
    # En-t√™tes
    writer.writerow(['Rang', 'Titre', 'URL', 'Domaine', 'Score', 'Snippet', 'Source'])
    
    # Donn√©es
    for i, link in enumerate(links, 1):
        writer.writerow([
            i,
            link['title'],
            link['url'],
            extract_domain(link['url']),
            f"{link.get('relevance_score', 0):.1f}",
            link.get('snippet', '')[:200],
            link.get('source', 'N/A')
        ])
    
    return output.getvalue()

def display_detailed_results_table(result):
    """Affiche un tableau d√©taill√© des r√©sultats de recherche"""
    st.markdown("### üìä Tableau d√©taill√© des r√©sultats")
    
    # Cr√©er les donn√©es pour le tableau
    table_data = []
    
    # Ajouter les sources de recherche
    for i, source in enumerate(result.get('search_results', []), 1):
        table_data.append({
            'N¬∞': i,
            'Type': 'üîç Source',
            'Titre': source.get('title', 'N/A')[:60] + '...' if len(source.get('title', '')) > 60 else source.get('title', 'N/A'),
            'URL': source.get('url', 'N/A'),
            'Moteur': source.get('source', 'N/A'),
            'Snippet': source.get('snippet', 'N/A')[:100] + '...' if len(source.get('snippet', '')) > 100 else source.get('snippet', 'N/A'),
            'Status': '‚úÖ Trouv√©'
        })
    
    # Ajouter les articles scrap√©s
    for i, article in enumerate(result.get('scraped_articles', []), 1):
        table_data.append({
            'N¬∞': len(result.get('search_results', [])) + i,
            'Type': 'üì∞ Article',
            'Titre': article.get('title', 'N/A')[:60] + '...' if len(article.get('title', '')) > 60 else article.get('title', 'N/A'),
            'URL': article.get('url', 'N/A'),
            'Moteur': 'Scraped',
            'Snippet': article.get('content', 'N/A')[:100] + '...' if len(article.get('content', '')) > 100 else article.get('content', 'N/A'),
            'Status': '‚úÖ Analys√©'
        })
    
    # Cr√©er le DataFrame
    if table_data:
        df = pd.DataFrame(table_data)
        
        # Afficher le tableau avec style
        st.dataframe(
            df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "N¬∞": st.column_config.NumberColumn("N¬∞", width="small"),
                "Type": st.column_config.TextColumn("Type", width="small"),
                "Titre": st.column_config.TextColumn("Titre", width="medium"),
                "URL": st.column_config.LinkColumn("URL", width="medium"),
                "Moteur": st.column_config.TextColumn("Moteur", width="small"),
                "Snippet": st.column_config.TextColumn("Extrait", width="large"),
                "Status": st.column_config.TextColumn("Status", width="small")
            }
        )
        
        # Statistiques
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìä Total r√©sultats", len(table_data))
        with col2:
            sources_count = len(result.get('search_results', []))
            st.metric("üîç Sources trouv√©es", sources_count)
        with col3:
            articles_count = len(result.get('scraped_articles', []))
            st.metric("üì∞ Articles analys√©s", articles_count)
        with col4:
            if result.get('plan'):
                queries_count = len(result['plan'].get('requetes_recherche', []))
                st.metric("üéØ Requ√™tes ex√©cut√©es", queries_count)
    else:
        st.warning("Aucun r√©sultat √† afficher dans le tableau")

def display_research_insights(result):
    """Affiche des insights d√©taill√©s sur la recherche"""
    st.markdown("### üî¨ Analyse approfondie de la recherche")
    
    # Plan de recherche d√©taill√© et intelligent
    if result.get('plan'):
        plan = result['plan']
        with st.expander("üìã Plan de recherche intelligent", expanded=True):
            # Analyse de la question
            if plan.get('analyse'):
                st.info(f"üß† **Analyse de votre question :** {plan['analyse']}")
            
            # Plan d'action structur√©
            if plan.get('plan_etapes'):
                st.markdown("**üìä Plan d'action en √©tapes :**")
                for i, etape in enumerate(plan['plan_etapes'], 1):
                    st.markdown(f"  {i}. {etape}")
                st.markdown("---")
            
            # Requ√™tes de recherche
            st.markdown("**üéØ Requ√™tes de recherche optimis√©es :**")
            for i, query in enumerate(plan.get('requetes_recherche', []), 1):
                st.markdown(f"  {i}. `{query}`")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if plan.get('types_sources'):
                    st.markdown("**üìö Types de sources cibl√©es :**")
                    for source_type in plan['types_sources']:
                        st.markdown(f"  ‚Ä¢ {source_type}")
            
            with col2:
                if plan.get('questions_secondaires'):
                    st.markdown("**‚ùì Questions secondaires √† explorer :**")
                    for question in plan['questions_secondaires']:
                        st.markdown(f"  ‚Ä¢ {question}")
            
            if plan.get('strategie'):
                st.markdown(f"**üé≤ Strat√©gie :** {plan['strategie']}")
    
    # Analyse des sources
    if result.get('search_results'):
        with st.expander("üîç Analyse des sources", expanded=True):
            sources = result['search_results']
            
            # R√©partition par moteur de recherche
            source_counts = {}
            for source in sources:
                engine = source.get('source', 'Inconnu')
                source_counts[engine] = source_counts.get(engine, 0) + 1
            
            st.markdown("**üìä R√©partition par moteur de recherche :**")
            for engine, count in source_counts.items():
                percentage = (count / len(sources)) * 100
                st.markdown(f"  ‚Ä¢ {engine}: {count} r√©sultats ({percentage:.1f}%)")
            
            # Analyse des domaines
            domains = {}
            for source in sources:
                url = source.get('url', '')
                if url:
                    try:
                        domain = url.split('/')[2]
                        domains[domain] = domains.get(domain, 0) + 1
                    except:
                        pass
            
            if domains:
                st.markdown("**üåê Domaines les plus fr√©quents :**")
                sorted_domains = sorted(domains.items(), key=lambda x: x[1], reverse=True)
                for domain, count in sorted_domains[:10]:
                    st.markdown(f"  ‚Ä¢ {domain}: {count} r√©sultat(s)")
    
    # Qualit√© du scraping
    if result.get('scraped_articles'):
        with st.expander("üì∞ Qualit√© du scraping", expanded=True):
            articles = result['scraped_articles']
            
            # Statistiques de longueur
            lengths = [len(article.get('content', '')) for article in articles]
            if lengths:
                avg_length = sum(lengths) / len(lengths)
                st.markdown(f"**üìè Longueur moyenne des articles :** {avg_length:.0f} caract√®res")
                st.markdown(f"**üìè Article le plus long :** {max(lengths)} caract√®res")
                st.markdown(f"**üìè Article le plus court :** {min(lengths)} caract√®res")
            
            # Articles avec dates
            dated_articles = [a for a in articles if a.get('publish_date')]
            st.markdown(f"**üìÖ Articles avec date :** {len(dated_articles)}/{len(articles)}")
            
            # Articles avec auteurs
            authored_articles = [a for a in articles if a.get('authors')]
            st.markdown(f"**üë§ Articles avec auteur :** {len(authored_articles)}/{len(articles)}")

def display_advanced_metrics(result):
    """Affiche des m√©triques avanc√©es sur la recherche"""
    st.markdown("### üìà M√©triques avanc√©es")
    
    # M√©triques de performance
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ‚ö° Performance")
        
        # Calcul du taux de succ√®s
        total_searches = len(result.get('search_results', []))
        successful_scrapes = len(result.get('scraped_articles', []))
        
        if total_searches > 0:
            success_rate = (successful_scrapes / total_searches) * 100
            st.metric("üéØ Taux de succ√®s du scraping", f"{success_rate:.1f}%")
        
        # Vitesse de recherche
        if result.get('stats', {}).get('total_duration'):
            duration_str = result['stats']['total_duration']
            try:
                duration_seconds = float(duration_str.replace('s', ''))
                speed = total_searches / duration_seconds if duration_seconds > 0 else 0
                st.metric("üöÄ Vitesse de recherche", f"{speed:.1f} r√©sultats/s")
            except:
                st.metric("üöÄ Vitesse de recherche", "N/A")
        
        # Efficacit√© du plan
        if result.get('plan'):
            queries_planned = len(result['plan'].get('requetes_recherche', []))
            queries_used = result.get('stats', {}).get('search_queries_used', 0)
            if queries_planned > 0:
                plan_efficiency = (queries_used / queries_planned) * 100
                st.metric("üìã Efficacit√© du plan", f"{plan_efficiency:.1f}%")
    
    with col2:
        st.markdown("#### üîç Qualit√© des donn√©es")
        
        # Richesse du contenu
        if result.get('scraped_articles'):
            articles = result['scraped_articles']
            
            # Longueur moyenne
            lengths = [len(article.get('content', '')) for article in articles]
            if lengths:
                avg_length = sum(lengths) / len(lengths)
                st.metric("üìè Longueur moyenne", f"{avg_length:.0f} chars")
            
            # Diversit√© des sources
            unique_domains = set()
            for article in articles:
                url = article.get('url', '')
                if url:
                    try:
                        domain = url.split('/')[2]
                        unique_domains.add(domain)
                    except:
                        pass
            
            if unique_domains:
                diversity = len(unique_domains) / len(articles) * 100
                st.metric("üåê Diversit√© des sources", f"{diversity:.1f}%")
            
            # Fra√Æcheur des donn√©es
            recent_articles = 0
            for article in articles:
                if article.get('publish_date'):
                    # Logique simple pour d√©terminer si c'est r√©cent
                    recent_articles += 1
            
            if articles:
                freshness = (recent_articles / len(articles)) * 100
                st.metric("üìÖ Fra√Æcheur des donn√©es", f"{freshness:.1f}%")
    
    # Graphique de r√©partition des sources
    if result.get('search_results'):
        st.markdown("#### üìä R√©partition des sources par moteur")
        
        sources = result['search_results']
        source_counts = {}
        for source in sources:
            engine = source.get('source', 'Inconnu')
            source_counts[engine] = source_counts.get(engine, 0) + 1
        
        # Cr√©er un DataFrame pour le graphique
        if source_counts:
            chart_data = pd.DataFrame(
                list(source_counts.items()),
                columns=['Moteur', 'Nombre']
            )
            
            # Graphique en barres
            st.bar_chart(chart_data.set_index('Moteur'))
            
            # Tableau de d√©tail
            st.markdown("**D√©tail par moteur :**")
            for engine, count in sorted(source_counts.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / len(sources)) * 100
                st.write(f"‚Ä¢ **{engine}**: {count} r√©sultats ({percentage:.1f}%)")
    
    # Recommandations d'am√©lioration
    st.markdown("#### üí° Recommandations")
    
    recommendations = []
    
    # Analyse du taux de succ√®s
    if total_searches > 0:
        success_rate = (successful_scrapes / total_searches) * 100
        if success_rate < 50:
            recommendations.append("üîß Am√©liorer la s√©lection des sources pour augmenter le taux de scraping")
        elif success_rate > 80:
            recommendations.append("‚úÖ Excellent taux de scraping ! Maintenir la qualit√©")
    
    # Analyse de la diversit√©
    if result.get('scraped_articles'):
        unique_domains = set()
        for article in result['scraped_articles']:
            url = article.get('url', '')
            if url:
                try:
                    domain = url.split('/')[2]
                    unique_domains.add(domain)
                except:
                    pass
        
        if len(unique_domains) < 3:
            recommendations.append("üåê Diversifier les sources pour obtenir des perspectives vari√©es")
    
    # Analyse de la longueur
    if result.get('scraped_articles'):
        lengths = [len(article.get('content', '')) for article in result['scraped_articles']]
        if lengths and sum(lengths) / len(lengths) < 500:
            recommendations.append("üìè Chercher des articles plus d√©taill√©s pour une meilleure analyse")
    
    if recommendations:
        for rec in recommendations:
            st.write(rec)
    else:
        st.write("‚úÖ Excellente recherche ! Aucune am√©lioration majeure n√©cessaire.")

def display_plan_preview(plan, user_query):
    """Affiche la pr√©visualisation du plan de recherche avec options"""
    st.markdown("### üìã Pr√©visualisation du plan de recherche")
    
    # Affichage du plan dans un style attractif
    with st.container():
        # En-t√™te avec la question
        st.info(f"üéØ **Question analys√©e :** {user_query}")
        
        # Analyse de la question (si disponible)
        if plan.get('analyse'):
            st.markdown(f"üß† **Analyse :** {plan['analyse']}")
        
        # Plan d'action en √©tapes
        if plan.get('plan_etapes'):
            st.markdown("**üìä Plan d'action :**")
            for i, etape in enumerate(plan['plan_etapes'], 1):
                st.markdown(f"   {i}. {etape}")
        
        # Requ√™tes de recherche pr√©vues
        st.markdown("**üîç Requ√™tes de recherche qui seront ex√©cut√©es :**")
        queries = plan.get('requetes_recherche', [])
        for i, query in enumerate(queries, 1):
            st.markdown(f"   {i}. `{query}`")
        
        # Informations compl√©mentaires
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**üìö Types de sources cibl√©es :**")
            for source_type in plan.get('types_sources', []):
                st.markdown(f"   ‚Ä¢ {source_type}")
        
        with col2:
            st.markdown("**‚ùì Questions secondaires :**")
            for question in plan.get('questions_secondaires', []):
                st.markdown(f"   ‚Ä¢ {question}")
        
        # Strat√©gie
        if plan.get('strategie'):
            st.markdown(f"**üé≤ Strat√©gie :** {plan['strategie']}")
        
        st.markdown("---")
        
        # Boutons d'action
        col1, col2, col3 = st.columns([2, 2, 1])
        
        with col1:
            if st.button("‚úÖ Accepter ce plan et lancer la recherche", type="primary", use_container_width=True):
                st.session_state.plan_approved = True
                # Ne pas effacer le plan ici - il sera effac√© apr√®s la recherche
                st.rerun()
        
        with col2:
            if st.button("üîÑ G√©n√©rer un nouveau plan", type="secondary", use_container_width=True):
                st.session_state.regenerate_plan = True
                st.rerun()
        
        with col3:
            if st.button("‚ùå Annuler", use_container_width=True):
                st.session_state.preview_plan = None
                st.session_state.plan_approved = False
                st.rerun()
        
        # Message d'aide
        st.markdown("üí° **Conseil :** V√©rifiez que les requ√™tes couvrent bien tous les aspects de votre question avant de lancer la recherche.")

def display_followup_interface(result):
    """Affiche l'interface pour poser des questions de suivi"""
    st.markdown("---")
    st.markdown("### üîÑ Questions de suivi")
    st.markdown("Posez une question compl√©mentaire bas√©e sur les r√©sultats obtenus. L'IA utilisera le contexte de votre recherche pr√©c√©dente.")
    
    # Suggestions de questions bas√©es sur les r√©sultats
    with st.expander("üí° Suggestions de questions de suivi", expanded=False):
        suggestions = generate_followup_suggestions(result)
        st.markdown("**Voici quelques questions que vous pourriez poser :**")
        
        for i, suggestion in enumerate(suggestions, 1):
            col1, col2 = st.columns([3, 1])
            with col1:
                st.markdown(f"{i}. {suggestion}")
            with col2:
                if st.button(f"Utiliser", key=f"suggestion_{i}"):
                    st.session_state.followup_query = suggestion
                    st.rerun()
    
    # Champ de saisie pour la question de suivi
    followup_query = st.text_input(
        "ü§î Votre question de suivi :",
        value=st.session_state.get('followup_query', ''),
        placeholder="Ex: Quels sont les risques de cette approche ? / Peut-on avoir plus de d√©tails sur... ?",
        help="Cette question sera enrichie avec le contexte de votre recherche pr√©c√©dente"
    )
    
    # Boutons d'action
    col1, col2, col3 = st.columns([2, 2, 1])
    
    with col1:
        if st.button("üîç Recherche contextuelle", type="primary", use_container_width=True, disabled=not followup_query.strip()):
            # Lancer une recherche contextuelle
            st.session_state.followup_query = followup_query.strip()
            st.session_state.contextual_search_active = True
            st.session_state.research_context = result
            st.rerun()
    
    with col2:
        if st.button("üîÑ Nouvelle recherche compl√®te", type="secondary", use_container_width=True):
            # Effacer le contexte et commencer une nouvelle recherche
            st.session_state.research_context = None
            st.session_state.research_chain = []
            st.session_state.last_result = None
            st.session_state.followup_query = ""
            st.info("üí´ Contexte effac√©. Vous pouvez maintenant faire une nouvelle recherche compl√®te.")
            st.rerun()
    
    with col3:
        if st.button("üìã Historique", use_container_width=True):
            show_research_chain()
    
    # Afficher la cha√Æne de recherches si elle existe
    if st.session_state.research_chain:
        with st.expander(f"üîó Cha√Æne de recherches ({len(st.session_state.research_chain)} √©tapes)", expanded=False):
            for i, search_item in enumerate(st.session_state.research_chain, 1):
                st.markdown(f"**{i}. {search_item['type']}:** {search_item['query']}")
                if search_item.get('summary'):
                    st.caption(f"üìù {search_item['summary'][:100]}...")

def generate_followup_suggestions(result):
    """G√©n√®re des suggestions de questions de suivi bas√©es sur les r√©sultats"""
    original_query = result.get('query', '')
    plan = result.get('plan', {})
    
    suggestions = []
    
    # Suggestions bas√©es sur les questions secondaires du plan
    if plan.get('questions_secondaires'):
        suggestions.extend(plan['questions_secondaires'][:2])
    
    # Suggestions g√©n√©riques adaptatives
    if 'avantages' in original_query.lower() or 'inconv√©nients' in original_query.lower():
        suggestions.append("Quelles sont les alternatives √† consid√©rer ?")
        suggestions.append("Y a-t-il des √©tudes r√©centes sur ce sujet ?")
    elif 'comment' in original_query.lower():
        suggestions.append("Quels sont les risques ou pr√©cautions √† prendre ?")
        suggestions.append("Combien de temps faut-il pour voir des r√©sultats ?")
    elif 'comparaison' in original_query.lower() or 'vs' in original_query.lower():
        suggestions.append("Quels sont les crit√®res de choix les plus importants ?")
        suggestions.append("Y a-t-il d'autres options √† consid√©rer ?")
    else:
        suggestions.extend([
            "Quels sont les aspects les plus importants √† retenir ?",
            "Y a-t-il des d√©veloppements r√©cents sur ce sujet ?",
            "Quelles sont les meilleures pratiques recommand√©es ?",
            "Peut-on avoir des exemples concrets ?",
            "Quels sont les points de vigilance ?"
        ])
    
    return suggestions[:5]  # Limiter √† 5 suggestions

def show_research_chain():
    """Affiche la cha√Æne compl√®te des recherches dans une modal"""
    if st.session_state.research_chain:
        st.markdown("#### üîó Historique complet des recherches")
        for i, search_item in enumerate(st.session_state.research_chain, 1):
            with st.container():
                st.markdown(f"**√âtape {i} - {search_item['type']}**")
                st.markdown(f"üéØ **Question :** {search_item['query']}")
                if search_item.get('summary'):
                    st.markdown(f"üìù **R√©sum√© :** {search_item['summary']}")
                st.markdown("---")
    else:
        st.info("Aucun historique de recherche pour le moment.")

def contextual_research_with_progress(agent, followup_query, context_result, max_articles=5, search_engines=None, scraping_method="both", max_results=10, max_queries=6):
    """Effectue une recherche contextuelle enrichie avec les r√©sultats pr√©c√©dents"""
    tracker = SearchProgressTracker()
    
    if search_engines is None:
        search_engines = ["SerpApi", "SearXNG"]
    
    try:
        # V√©rifier si la recherche doit continuer
        if not st.session_state.get('search_running', True):
            logger.info("üõë Recherche contextuelle interrompue par l'utilisateur")
            return None
        
        # √âtape 1: Enrichissement contextuel de la question
        tracker.start_step("context", "Enrichissement contextuel", "Analyse de votre question avec le contexte pr√©c√©dent")
        
        # Cr√©er un prompt enrichi qui inclut le contexte
        context_prompt = create_contextual_prompt(followup_query, context_result)
        
        # G√©n√©rer un plan intelligent enrichi avec le contexte
        plan = agent.llm_client.generate_contextual_search_plan(context_prompt, context_result)
        
        # Limiter le nombre de requ√™tes
        all_queries = plan.get("requetes_recherche", [followup_query])
        limited_queries = all_queries[:max_queries]
        queries_count = len(limited_queries)
        
        tracker.complete_step("context", "Contexte int√©gr√©", f"{queries_count} requ√™tes contextuelles g√©n√©r√©es")
        
        # √âtape 2: Recherche web contextuelle
        tracker.start_step("search", "Recherche contextuelle", f"Recherche enrichie avec {queries_count} requ√™tes")
        all_search_results = []
        
        for i, search_query in enumerate(limited_queries, 1):
            if not st.session_state.get('search_running', True):
                logger.info("üõë Recherche interrompue pendant la recherche web contextuelle")
                return None
                
            add_search_log(f"üîç Requ√™te contextuelle {i}/{queries_count}: {search_query}")
            results = agent.search_api.search_web(search_query, max_results=max_results, enabled_engines=search_engines)
            all_search_results.extend(results)
            
            progress_details = f"Requ√™te contextuelle {i}/{queries_count} - {len(results)} r√©sultats"
            update_search_step("search", "active", "Recherche contextuelle", progress_details)
        
        # Supprimer les doublons
        unique_results = []
        seen_urls = set()
        for result in all_search_results:
            if result['url'] not in seen_urls:
                seen_urls.add(result['url'])
                unique_results.append(result)
        
        tracker.complete_step("search", "Recherche contextuelle termin√©e", f"{len(unique_results)} nouveaux r√©sultats trouv√©s")
        
        # √âtape 3: Scraping contextuel
        if not st.session_state.get('search_running', True):
            logger.info("üõë Recherche interrompue avant le scraping contextuel")
            return None
            
        tracker.start_step("scraping", "Analyse contextuelle", f"Extraction de {min(len(unique_results), max_articles)} nouvelles sources")
        urls_to_scrape = [result['url'] for result in unique_results[:max_articles * 2]]
        scraped_articles = agent.scraper.scrape_multiple_urls(urls_to_scrape, max_articles=max_articles, method=scraping_method)
        
        tracker.complete_step("scraping", "Articles contextuels analys√©s", f"{len(scraped_articles)} nouveaux articles extraits")
        
        # √âtape 4: Synth√®se contextuelle enrichie
        if not st.session_state.get('search_running', True):
            logger.info("üõë Recherche interrompue avant la synth√®se contextuelle")
            return None
            
        tracker.start_step("synthesis", "Synth√®se contextuelle", "Int√©gration avec les r√©sultats pr√©c√©dents")
        
        # Synth√®se qui int√®gre le contexte pr√©c√©dent
        synthesis = agent.llm_client.synthesize_contextual_results(
            followup_query, 
            unique_results, 
            scraped_articles, 
            context_result
        )
        
        tracker.complete_step("synthesis", "Synth√®se contextuelle termin√©e", "R√©sultats int√©gr√©s avec le contexte")
        
        # Pr√©parer le r√©sultat final contextuel
        result = {
            "query": followup_query,
            "original_query": context_result.get('query', ''),
            "is_contextual": True,
            "context_summary": context_result.get('synthesis', '')[:300] + "...",
            "plan": plan,
            "search_results": unique_results,
            "scraped_articles": scraped_articles,
            "synthesis": synthesis,
            "stats": {
                "search_results_count": len(unique_results),
                "scraped_articles_count": len(scraped_articles),
                "search_queries_used": len(plan.get("requetes_recherche", [])),
                "total_duration": tracker.get_total_duration()
            }
        }
        
        # Ajouter √† la cha√Æne de recherches
        add_to_research_chain("Recherche contextuelle", followup_query, synthesis[:200] + "...")
        
        logger.info("‚úÖ Recherche contextuelle termin√©e avec succ√®s")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Erreur recherche contextuelle: {e}")
        tracker.mark_error("synthesis", "Erreur synth√®se", str(e))
        raise e

def create_contextual_prompt(followup_query, context_result):
    """Cr√©e un prompt enrichi avec le contexte de la recherche pr√©c√©dente"""
    original_query = context_result.get('query', '')
    original_synthesis = context_result.get('synthesis', '')[:500]  # Limiter la taille
    
    context_prompt = f"""Question originale: "{original_query}"

R√©sum√© des r√©sultats pr√©c√©dents:
{original_synthesis}

Question de suivi: "{followup_query}"

Contexte: L'utilisateur pose cette question de suivi bas√©e sur les r√©sultats de sa recherche pr√©c√©dente. La nouvelle recherche doit √™tre enrichie et compl√©mentaire."""
    
    return context_prompt

def add_to_research_chain(search_type, query, summary):
    """Ajoute une recherche √† la cha√Æne d'historique"""
    if 'research_chain' not in st.session_state:
        st.session_state.research_chain = []
    
    st.session_state.research_chain.append({
        'type': search_type,
        'query': query,
        'summary': summary,
        'timestamp': time.strftime("%H:%M:%S")
    })
    
    # Limiter √† 10 √©l√©ments pour √©viter une cha√Æne trop longue
    if len(st.session_state.research_chain) > 10:
        st.session_state.research_chain = st.session_state.research_chain[-10:]

def main():
    """Fonction principale"""
    init_session_state()
    display_header()
    display_sidebar()
    
    # Interface de recherche
    user_query, search_button, show_logs, deep_search, max_articles, llm_provider, search_engines, scraping_method, max_results, max_queries = display_search_interface()
    
    # Afficher le progr√®s s'il y en a un
    if st.session_state.search_steps:
        display_search_progress()
        
        # Bouton d'arr√™t pendant la recherche
        if st.session_state.get('search_running', False):
            if st.button("üõë ARR√äTER LA RECHERCHE", type="secondary", use_container_width=True):
                st.session_state.search_running = False
                add_search_log("üõë Recherche arr√™t√©e par l'utilisateur", "warning")
                st.warning("üõë Arr√™t de la recherche en cours...")
                st.rerun()
    
    # Afficher les logs en temps r√©el si recherche en cours
    if st.session_state.get('search_running', False) or show_logs:
        if st.session_state.search_logs:
            st.markdown("### üìã Logs en temps r√©el")
            
            # Conteneur de logs avec scroll automatique
            log_container = st.container()
            with log_container:
                # Afficher les 15 derniers logs
                recent_logs = st.session_state.search_logs[-15:] if len(st.session_state.search_logs) > 15 else st.session_state.search_logs
                
                for log in recent_logs:
                    # Couleurs selon le niveau et contenu
                    if "‚úÖ" in log["message"] or "r√©ussie" in log["message"]:
                        st.success(f"[{log['time']}] {log['message']}")
                    elif "üõë" in log["message"] or "interrompue" in log["message"]:
                        st.warning(f"[{log['time']}] {log['message']}")
                    elif "‚ö†Ô∏è" in log["message"] or "erreur" in log["message"]:
                        st.warning(f"[{log['time']}] {log['message']}")
                    elif "‚ùå" in log["message"]:
                        st.error(f"[{log['time']}] {log['message']}")
                    elif "üîç" in log["message"] or "üöÄ" in log["message"]:
                        st.info(f"[{log['time']}] {log['message']}")
                    else:
                        st.text(f"[{log['time']}] {log['message']}")
                
                # Auto-scroll vers le bas
                if st.session_state.get('search_running', False):
                    st.markdown('<script>window.scrollTo(0, document.body.scrollHeight);</script>', unsafe_allow_html=True)
    
    # ========== NOUVELLE LOGIQUE DE PR√âVISUALISATION DU PLAN ==========
    
    # 1. G√âN√âRATION DU PLAN (premi√®re √©tape)
    if search_button and user_query and not st.session_state.get('preview_plan'):
        # Nettoyer l'interface pour la nouvelle recherche
        st.session_state.last_result = None
        st.session_state.search_steps = {}
        st.session_state.search_logs = []
        st.session_state.plan_approved = False
        st.session_state.regenerate_plan = False
        
        # Configurer l'agent
        st.session_state.agent = get_agent(llm_provider, search_engines, scraping_method)
        st.session_state.current_query = user_query
        st.session_state.current_config = {
            'deep_search': deep_search,
            'max_articles': max_articles,
            'search_engines': search_engines,
            'scraping_method': scraping_method,
            'max_results': max_results,
            'max_queries': max_queries,
            'llm_provider': llm_provider
        }
        
        # G√©n√©rer le plan de recherche
        with st.spinner("üß† G√©n√©ration du plan de recherche..."):
            try:
                plan = st.session_state.agent.llm_client.generate_deep_search_plan(user_query)
                st.session_state.preview_plan = plan
                st.success("‚úÖ Plan de recherche g√©n√©r√© ! V√©rifiez-le ci-dessous.")
                st.rerun()
            except Exception as e:
                st.error(f"‚ùå Erreur lors de la g√©n√©ration du plan: {str(e)}")
    
    # 2. R√âG√âN√âRATION DU PLAN (si demand√©e)
    if st.session_state.get('regenerate_plan', False):
        st.session_state.regenerate_plan = False
        
        with st.spinner("üîÑ G√©n√©ration d'un nouveau plan..."):
            try:
                # R√©g√©n√©rer avec un prompt l√©g√®rement diff√©rent pour avoir de la vari√©t√©
                plan = st.session_state.agent.llm_client.generate_deep_search_plan(st.session_state.current_query)
                st.session_state.preview_plan = plan
                st.success("‚úÖ Nouveau plan g√©n√©r√© !")
                st.rerun()
            except Exception as e:
                st.error(f"‚ùå Erreur lors de la r√©g√©n√©ration: {str(e)}")
    
    # 3. AFFICHAGE DE LA PR√âVISUALISATION
    if st.session_state.get('preview_plan') and not st.session_state.get('plan_approved', False):
        display_plan_preview(st.session_state.preview_plan, st.session_state.current_query)
    
    # 4. LANCEMENT DE LA RECHERCHE (apr√®s approbation du plan)
    if st.session_state.get('plan_approved', False) and st.session_state.get('preview_plan'):
        # Ajouter √† l'historique
        if st.session_state.current_query not in st.session_state.search_history:
            st.session_state.search_history.append(st.session_state.current_query)
        
        # Marquer le d√©but de la recherche
        st.session_state.search_running = True
        
        # Messages de d√©marrage
        add_search_log("üßπ Interface nettoy√©e - Nouvelle recherche")
        config = st.session_state.current_config
        config_info = f"ü§ñ {config['llm_provider'].upper()} | üîç {', '.join(config['search_engines'])} | üì∞ {config['scraping_method']}"
        add_search_log(f"‚öôÔ∏è Configuration: {config_info}")
        add_search_log(f"üéØ Question: {st.session_state.current_query}")
        add_search_log("üìã Plan de recherche approuv√© par l'utilisateur")
        
        # Ajouter √† la cha√Æne de recherches (premi√®re recherche)
        add_to_research_chain("Recherche initiale", st.session_state.current_query, "Recherche lanc√©e...")
        
        # Placeholder pour les mises √† jour en temps r√©el
        progress_placeholder = st.empty()
        
        try:
            # Effectuer la recherche avec suivi (en utilisant le plan approuv√©)
            with st.spinner("üîÑ Recherche en cours..."):
                result = research_with_progress_tracking(
                    st.session_state.agent, 
                    st.session_state.current_query, 
                    deep_search=config['deep_search'], 
                    max_articles=config['max_articles'],
                    search_engines=config['search_engines'],
                    scraping_method=config['scraping_method'],
                    max_results=config['max_results'],
                    max_queries=config['max_queries'],
                    predefined_plan=st.session_state.preview_plan  # Passer le plan approuv√©
                )
                
                # V√©rifier si la recherche a √©t√© interrompue
                if result is None:
                    st.warning("üõë Recherche interrompue par l'utilisateur")
                    st.session_state.search_running = False
                    return
                
                st.session_state.last_result = result
                
                # Mettre √† jour la cha√Æne avec le r√©sum√©
                if st.session_state.research_chain:
                    st.session_state.research_chain[-1]['summary'] = result.get('synthesis', '')[:200] + "..."
            
            st.success("‚úÖ Recherche termin√©e avec succ√®s !")
            st.session_state.search_running = False
            
            # Nettoyer les √©tats de plan
            st.session_state.plan_approved = False
            st.session_state.preview_plan = None
            
        except Exception as e:
            st.session_state.search_running = False
            st.error(f"‚ùå Erreur lors de la recherche: {str(e)}")
            logger.error(f"Erreur recherche: {e}")
            
            # Afficher les d√©tails de l'erreur
            with st.expander("üîç D√©tails de l'erreur"):
                st.code(str(e))
                st.write("**Logs de debug :**")
                for log in st.session_state.search_logs[-10:]:
                    st.write(f"[{log['time']}] {log['message']}")
    
    # ========== NOUVELLE LOGIQUE DE RECHERCHE CONTEXTUELLE ==========
    
    # 5. GESTION DE LA RECHERCHE CONTEXTUELLE
    if st.session_state.get('contextual_search_active', False):
        st.session_state.contextual_search_active = False
        
        # Nettoyer les logs et √©tapes pour la nouvelle recherche
        st.session_state.search_steps = {}
        st.session_state.search_logs = []
        
        # Marquer le d√©but de la recherche contextuelle
        st.session_state.search_running = True
        
        # Configurer l'agent (utiliser la config pr√©c√©dente ou par d√©faut)
        if not hasattr(st.session_state, 'agent') or st.session_state.agent is None:
            st.session_state.agent = get_agent("mistral", ["SerpApi"], "both")
        
        # Messages de d√©marrage pour la recherche contextuelle
        add_search_log("üîÑ D√©marrage de la recherche contextuelle")
        add_search_log(f"üí° Question de suivi: {st.session_state.followup_query}")
        add_search_log(f"üìö Utilisation du contexte de: {st.session_state.research_context.get('query', 'N/A')}")
        
        try:
            # Effectuer la recherche contextuelle
            with st.spinner("üîÑ Recherche contextuelle en cours..."):
                contextual_result = contextual_research_with_progress(
                    st.session_state.agent,
                    st.session_state.followup_query,
                    st.session_state.research_context,
                    max_articles=5,
                    search_engines=["SerpApi"],
                    scraping_method="both",
                    max_results=10,
                    max_queries=4  # Moins de requ√™tes pour les recherches de suivi
                )
                
                # V√©rifier si la recherche a √©t√© interrompue
                if contextual_result is None:
                    st.warning("üõë Recherche contextuelle interrompue par l'utilisateur")
                    st.session_state.search_running = False
                    return
                
                st.session_state.last_result = contextual_result
            
            st.success("‚úÖ Recherche contextuelle termin√©e avec succ√®s !")
            st.session_state.search_running = False
            
            # Nettoyer les √©tats
            st.session_state.followup_query = ""
            
        except Exception as e:
            st.session_state.search_running = False
            st.error(f"‚ùå Erreur lors de la recherche contextuelle: {str(e)}")
            logger.error(f"Erreur recherche contextuelle: {e}")
            
            # Afficher les d√©tails de l'erreur
            with st.expander("üîç D√©tails de l'erreur"):
                st.code(str(e))
                st.write("**Logs de debug :**")
                for log in st.session_state.search_logs[-10:]:
                    st.write(f"[{log['time']}] {log['message']}")
    
    # Afficher les r√©sultats
    if st.session_state.last_result:
        # Afficher un badge pour les r√©sultats contextuels
        if st.session_state.last_result.get('is_contextual', False):
            st.info(f"üîó **R√©sultats contextuels** bas√©s sur votre recherche pr√©c√©dente: \"{st.session_state.last_result.get('original_query', 'N/A')}\"")
        
        display_results(st.session_state.last_result)
    
    # Instructions (seulement si pas de plan en cours et pas de r√©sultats)
    if not st.session_state.last_result and not st.session_state.get('preview_plan'):
        st.markdown("""
        ### üí° Guide d'utilisation
        
        1. **Posez votre question** dans le champ ci-dessus
        2. **Cliquez sur "Lancer la recherche"** pour g√©n√©rer le plan
        3. **V√©rifiez le plan de recherche** propos√© par l'IA
        4. **Acceptez ou r√©g√©n√©rez** le plan selon vos besoins
        5. **Suivez le progr√®s** en temps r√©el avec les √©tapes color√©es
        6. **Explorez les r√©sultats** avec les sources et articles d√©taill√©s
        7. **Posez des questions de suivi** pour approfondir sans perdre le contexte
        
        **‚ú® Exemples de questions efficaces :**
        - `Intelligence artificielle avantages inconv√©nients`
        - `T√©l√©travail impact productivit√© 2024`
        - `Changement climatique solutions`
        - `Je√ªne intermittent effets sant√©`
        
        **üîÑ Exemples de questions de suivi :**
        - `Quels sont les risques de cette approche ?`
        - `Peut-on avoir des exemples concrets ?`
        - `Y a-t-il des alternatives ?`
        
        **üîß Activez les logs** pour voir les d√©tails techniques de la recherche.
        """)

if __name__ == "__main__":
    main() 